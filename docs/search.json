[
  {
    "objectID": "posts/Statistics/RMANOVA.html",
    "href": "posts/Statistics/RMANOVA.html",
    "title": "重复测量方差分析",
    "section": "",
    "text": "含分组因子的重复测量\nShow the code# 加载必要的包\nlibrary(tidyverse)\nlibrary(afex)      # 进行方差分析\nlibrary(emmeans)   # 事后分析\nlibrary(car)       # 用于假设检验\nlibrary(MASS)      # 用于正态性检验\n\n\nset.seed(123)\ndf &lt;- tibble(\n    id=1:30 %&gt;% as.factor(),\n    group = rep(c(\"A\",\"B\",\"C\"), each = 10) %&gt;% as.factor(),\n    t1 = rnorm(30, mean = 8, sd = 1),\n    t2 = rnorm(30, mean = 7, sd = 2),\n    t3 = rnorm(30, mean = 3, sd = 1)\n    \n)\n# 数据准备：已转换为长格式的 df_long\ndf_long &lt;- df %&gt;%\n    pivot_longer(cols = starts_with(\"t\"),\n                 names_to = \"time\",\n                 values_to = \"volume\") %&gt;%\n    mutate(time = factor(time, levels = c(\"t1\", \"t2\", \"t3\")),\n           group = factor(group))\nShow the code# 重复测量方差分析\nanova_results &lt;- aov_ez(id = \"id\", \n                        dv = \"volume\", \n                        within = \"time\", \n                        between = \"group\", \n                        data = df_long)\nanova_results %&gt;% summary()\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n            Sum Sq num Df Error SS den Df   F value Pr(&gt;F)    \n(Intercept) 3361.4      1   32.358     27 2804.7682 &lt;2e-16 ***\ngroup          1.7      2   32.358     27    0.7143 0.4986    \ntime         434.1      2   91.436     54  128.1956 &lt;2e-16 ***\ngroup:time     5.2      4   91.436     54    0.7746 0.5465    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMauchly Tests for Sphericity\n\n           Test statistic   p-value\ntime               0.5916 0.0010873\ngroup:time         0.5916 0.0010873\n\n\nGreenhouse-Geisser and Huynh-Feldt Corrections\n for Departure from Sphericity\n\n            GG eps Pr(&gt;F[GG])    \ntime       0.71002  9.551e-16 ***\ngroup:time 0.71002      0.509    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n              HF eps   Pr(&gt;F[HF])\ntime       0.7381052 2.805049e-16\ngroup:time 0.7381052 5.132499e-01\nShow the codeanova_results$lm\n\n\nCall:\nlm(formula = cbind(t1, t2, t3) ~ group, data = structure(list(\n    id = structure(1:30, levels = c(\"1\", \"2\", \"3\", \"4\", \"5\", \n    \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \n    \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \n    \"27\", \"28\", \"29\", \"30\"), class = \"factor\"), group = structure(c(1L, \n    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, \n    2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), levels = c(\"A\", \n    \"B\", \"C\"), class = \"factor\", contrasts = \"contr.sum\"), t1 = c(7.43952435344779, \n    7.76982251051672, 9.55870831414912, 8.07050839142458, 8.12928773516095, \n    9.71506498688328, 8.4609162059892, 6.73493876539347, 7.31314714810647, \n    7.55433802990004, 9.22408179743946, 8.35981382705736, 8.40077145059405, \n    8.11068271594512, 7.44415886524593, 9.78691313680308, 8.49785047822924, \n    6.03338284337036, 8.70135590156369, 7.52720859227207, 6.93217629401316, \n    7.78202508534171, 6.97399555169276, 7.27110877070886, 7.37496073215074, \n    6.31330668925759, 8.83778704449452, 8.15337311783652, 6.86186306298805, \n    9.25381492106993), t2 = c(7.85292844295363, 6.40985703401546, \n    8.79025132209004, 8.75626697506608, 8.64316216327497, 8.37728050820018, \n    8.10783530707518, 6.87617657884656, 6.38807467252017, 6.23905799797523, \n    5.61058604215897, 6.5841654439608, 4.46920729686347, 11.337911930677, \n    9.41592399660998, 4.7537828335933, 6.19423032940185, 6.06668929275356, \n    8.55993023667263, 6.83326186705634, 7.50663702798951, 6.94290648930259, \n    6.91425908541737, 9.73720456802891, 6.54845802868146, 10.0329412088591, \n    3.90249439153956, 8.16922749927214, 7.24770848768923, 7.43188313748795\n    ), t3 = c(3.37963948275988, 2.4976765468907, 2.66679261633058, \n    1.98142461689291, 1.92820877352442, 3.30352864140426, 3.44820977862943, \n    3.0530042267305, 3.92226746787974, 5.05008468562714, 2.50896883394346, \n    0.690831124359188, 4.00573852446226, 2.29079923741761, 2.31199138353264, \n    4.0255713696967, 2.71522699294899, 1.77928228774546, 3.18130347974915, \n    2.86110863756096, 3.00576418589989, 3.38528040112633, 2.62933996820759, \n    3.64437654851883, 2.77951343818125, 3.3317819639157, 4.09683901314935, \n    3.4351814908338, 2.67406841446877, 4.14880761845109)), row.names = c(NA, \n-30L), class = \"data.frame\"))\n\nCoefficients:\n             t1        t2        t3      \n(Intercept)   7.95290   7.35668   3.02442\ngroup1        0.12173   0.28741   0.09866\ngroup2        0.25573  -0.37411  -0.38734\n\nShow the codeanova_results$lm$contrasts\n\n$group\n[1] \"contr.sum\"\n\nShow the codecontr.sum(c(\"A\",\"B\",\"C\"))\n\n  [,1] [,2]\nA    1    0\nB    0    1\nC   -1   -1\n在 anova_results$lm 中，group 因子采用了 contr.sum 对比编码，而手动拟合的模型（lm(cbind(t1, t2, t3) ~ group, data = df)) 默认使用的是 contr.treatment，即 “treatment” 对比编码（参考水平为第一个因子水平）。这两种对比编码方式的结果系数解释略有不同，从而导致了系数值的差异。"
  },
  {
    "objectID": "posts/Statistics/RMANOVA.html#mlm",
    "href": "posts/Statistics/RMANOVA.html#mlm",
    "title": "重复测量方差分析",
    "section": "mlm",
    "text": "mlm\n\nShow the codelm_aov &lt;-  lm(formula = cbind(t1, t2, t3) ~ group, data = df)\n\nlm_aov$contrasts\n\n$group\n[1] \"contr.treatment\"\n\nShow the codecontr.treatment(c(\"A\",\"B\",\"C\"))\n\n  B C\nA 0 0\nB 1 0\nC 0 1\n\nShow the code# 使用 contr.sum 对比编码\ncontrasts(df$group) &lt;- contr.sum(levels(df$group))\n\n\ndf$group\n\n [1] A A A A A A A A A A B B B B B B B B B B C C C C C C C C C C\nattr(,\"contrasts\")\n  [,1] [,2]\nA    1    0\nB    0    1\nC   -1   -1\nLevels: A B C\n\nShow the codelm_aov2 &lt;-  lm(formula = cbind(t1, t2, t3) ~ group, data = df)\n\nlm_aov2\n\n\nCall:\nlm(formula = cbind(t1, t2, t3) ~ group, data = df)\n\nCoefficients:\n             t1        t2        t3      \n(Intercept)   7.95290   7.35668   3.02442\ngroup1        0.12173   0.28741   0.09866\ngroup2        0.25573  -0.37411  -0.38734\n\n\ncontr.treatment 编码（Treatment Coding）\n\n定义：也称为“dummy”编码或“参考水平编码”。\n目的：在回归模型中将第一个水平（参考水平）作为基准。\n机制：模型中每个因子水平的系数表示相对于参考水平的偏离。\n\n编码方式：例如对于一个三水平因子 group = {A, B, C}，使用 contr.treatment 时，模型中会以 A 作为基准，生成两个对比变量 groupB 和 groupC。这两个对比变量的系数解释如下：\n\ngroupB 的系数表示 B 相对于 A 的平均差异。\ngroupC 的系数表示 C 相对于 A 的平均差异。\n\n\n\ncontr.sum 编码（Sum Coding）\n\n定义：也称为“和对比编码”或“效果编码”。\n目的：确保所有因子水平的系数和为 0。\n机制：每个因子水平的系数表示该水平相对于因子的总体平均值的偏差。\n\n编码方式：对于同样的三水平因子 group = {A, B, C}，使用 contr.sum 时，模型会生成两个对比变量（与水平数减 1 一致），但它们的解释不同于 contr.treatment。\n\ngroup1 表示 A 和总体平均值的偏差。\ngroup2 表示 B 和总体平均值的偏差。\nC 的偏差通过 group1 和 group2 的相加可以得到。"
  },
  {
    "objectID": "posts/Statistics/RMANOVA.html#球形检验",
    "href": "posts/Statistics/RMANOVA.html#球形检验",
    "title": "重复测量方差分析",
    "section": "球形检验",
    "text": "球形检验\n检验方差-协方差矩阵是否满足球形假设\n\nShow the codedf_list &lt;- df %&gt;% group_split(group)\n\ndf_matrix &lt;- df_list %&gt;%\n  lapply(function(x) select(x, t1, t2, t3)) %&gt;%  # 提取t1, t2, t3列\n  bind_cols() %&gt;%  # 将每个数据框按列合并\n  as.matrix() \ncolnames(df_matrix) &lt;- paste(rep(c(\"A\", \"B\", \"C\"), each = 3), rep(1:3, 3), sep = \"\")\n\nrownames(df_matrix) &lt;- 1:10\ndf_matrix\n\n         A1       A2       A3       B1        B2        B3       C1        C2\n1  7.439524 7.852928 3.379639 9.224082  5.610586 2.5089688 6.932176  7.506637\n2  7.769823 6.409857 2.497677 8.359814  6.584165 0.6908311 7.782025  6.942906\n3  9.558708 8.790251 2.666793 8.400771  4.469207 4.0057385 6.973996  6.914259\n4  8.070508 8.756267 1.981425 8.110683 11.337912 2.2907992 7.271109  9.737205\n5  8.129288 8.643162 1.928209 7.444159  9.415924 2.3119914 7.374961  6.548458\n6  9.715065 8.377281 3.303529 9.786913  4.753783 4.0255714 6.313307 10.032941\n7  8.460916 8.107835 3.448210 8.497850  6.194230 2.7152270 8.837787  3.902494\n8  6.734939 6.876177 3.053004 6.033383  6.066689 1.7792823 8.153373  8.169227\n9  7.313147 6.388075 3.922267 8.701356  8.559930 3.1813035 6.861863  7.247708\n10 7.554338 6.239058 5.050085 7.527209  6.833262 2.8611086 9.253815  7.431883\n         C3\n1  3.005764\n2  3.385280\n3  2.629340\n4  3.644377\n5  2.779513\n6  3.331782\n7  4.096839\n8  3.435181\n9  2.674068\n10 4.148808\n\nShow the code# 多元线性回归\n\nmlmfit &lt;- lm(df_matrix ~ 1)  # 内部对比（intrasubject contrasts）\n\n\nmauchly.test(mlmfit, X = ~1) # 这个模型只是估计了反应变量的总体均值，忽略了任何自变量。换句话说，它只计算数据的平均值，并检查这些平均值是否满足球形假设。\n\n\n    Mauchly's test of sphericity\n    Contrasts orthogonal to\n    ~1\n\n\ndata:  SSD matrix from lm(formula = df_matrix ~ 1)\nW = 5.9785e-06, p-value = 0.000594\n\nShow the code# 列结构\n\nidata &lt;- data.frame(\n    Group = factor(rep(c(\"A\",\"B\",\"C\"),each = 3)),\n    Time = rep(1:3,3)\n)\n\nmlmfit &lt;- lm(cbind(t1,t2,t3) ~ group, data = df)\nmlmfit \n\n\nCall:\nlm(formula = cbind(t1, t2, t3) ~ group, data = df)\n\nCoefficients:\n             t1        t2        t3      \n(Intercept)   7.95290   7.35668   3.02442\ngroup1        0.12173   0.28741   0.09866\ngroup2        0.25573  -0.37411  -0.38734\n\nShow the codemanovafit &lt;- manova(cbind(t1, t2, t3) ~ group, data = df)\n\n\n\nShow the codereacttime &lt;- matrix(c(\n420, 420, 480, 480, 600, 780,\n420, 480, 480, 360, 480, 600,\n480, 480, 540, 660, 780, 780,\n420, 540, 540, 480, 780, 900,\n540, 660, 540, 480, 660, 720,\n360, 420, 360, 360, 480, 540,\n480, 480, 600, 540, 720, 840,\n480, 600, 660, 540, 720, 900,\n540, 600, 540, 480, 720, 780,\n480, 420, 540, 540, 660, 780),\nncol = 6, byrow = TRUE,\ndimnames = list(subj = 1:10,\n              cond = c(\"deg0NA\", \"deg4NA\", \"deg8NA\",\n                       \"deg0NP\", \"deg4NP\", \"deg8NP\")))\n\nmlmfit &lt;- lm(reacttime ~ 1)\n\nmlmfit\n\n\nCall:\nlm(formula = reacttime ~ 1)\n\nCoefficients:\n             deg0NA  deg4NA  deg8NA  deg0NP  deg4NP  deg8NP\n(Intercept)  462     510     528     492     660     762   \n\nShow the codemauchly.test(mlmfit, X = ~1)\n\n\n    Mauchly's test of sphericity\n    Contrasts orthogonal to\n    ~1\n\n\ndata:  SSD matrix from lm(formula = reacttime ~ 1)\nW = 0.031084, p-value = 0.04765\n\nShow the codeidata &lt;- data.frame(deg = gl(3, 1, 6, labels = c(0,4,8)),\n                    noise = gl(2, 3, 6, labels = c(\"A\",\"P\")))\n\n# 指定模型中的自变量 表示要检验这两个因素是否满足球形假设\nmauchly.test(mlmfit, X = ~ deg + noise, idata = idata)\n\n\n    Mauchly's test of sphericity\n    Contrasts orthogonal to\n    ~deg + noise\n\n\ndata:  SSD matrix from lm(formula = reacttime ~ 1)\nW = 0.89378, p-value = 0.6381\n\nShow the code# 指定模型中包含的因子（自变量） 仅检验 noise（即噪声条件的影响）是否满足球形假设。\nmauchly.test(mlmfit, M = ~ deg + noise, X = ~ noise, idata = idata)\n\n\n    Mauchly's test of sphericity\n    Contrasts orthogonal to\n    ~noise\n\n    Contrasts spanned by\n    ~deg + noise\n\n\ndata:  SSD matrix from lm(formula = reacttime ~ 1)\nW = 0.96011, p-value = 0.8497\n\n\n\nShow the codemauchly &lt;- df_long %&gt;% rstatix::anova_test(\n    dv = volume,\n    wid = id,\n    between = group,\n    within = time,\n    type = \"3\",detailed = T\n)\nmauchly$`Mauchly's Test for Sphericity`\n\n      Effect     W     p p&lt;.05\n1       time 0.592 0.001     *\n2 group:time 0.592 0.001     *\n\n\n\nShow the code# 正态性假设检验\nshapiro_test &lt;- by(df_long$volume, df_long$time, shapiro.test)\nshapiro_test\n\ndf_long$time: t1\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.97894, p-value = 0.7966\n\n------------------------------------------------------------ \ndf_long$time: t2\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.98662, p-value = 0.9614\n\n------------------------------------------------------------ \ndf_long$time: t3\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.98085, p-value = 0.8478\n\nShow the code# 成对比较\nemmeans_results &lt;- emmeans(anova_results, ~ group | time)\n\npairwise_comparisons &lt;- contrast(emmeans_results, method = \"pairwise\")\npairwise_comparisons\n\ntime = t1:\n contrast estimate    SE df t.ratio p.value\n A - B      -0.134 0.436 27  -0.307  0.9494\n A - C       0.499 0.436 27   1.144  0.4958\n B - C       0.633 0.436 27   1.452  0.3296\n\ntime = t2:\n contrast estimate    SE df t.ratio p.value\n A - B       0.662 0.763 27   0.867  0.6653\n A - C       0.201 0.763 27   0.263  0.9626\n B - C      -0.461 0.763 27  -0.604  0.8192\n\ntime = t3:\n contrast estimate    SE df t.ratio p.value\n A - B       0.486 0.380 27   1.278  0.4192\n A - C      -0.190 0.380 27  -0.500  0.8720\n B - C      -0.676 0.380 27  -1.778  0.1959\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\nShow the codeemmeans(anova_results, pairwise ~  time| group)\n\n$emmeans\ngroup = A:\n time emmean    SE df lower.CL upper.CL\n t1     8.07 0.308 27     7.44     8.71\n t2     7.64 0.540 27     6.54     8.75\n t3     3.12 0.269 27     2.57     3.67\n\ngroup = B:\n time emmean    SE df lower.CL upper.CL\n t1     8.21 0.308 27     7.58     8.84\n t2     6.98 0.540 27     5.88     8.09\n t3     2.64 0.269 27     2.09     3.19\n\ngroup = C:\n time emmean    SE df lower.CL upper.CL\n t1     7.58 0.308 27     6.94     8.21\n t2     7.44 0.540 27     6.34     8.55\n t3     3.31 0.269 27     2.76     3.86\n\nConfidence level used: 0.95 \n\n$contrasts\ngroup = A:\n contrast estimate    SE df t.ratio p.value\n t1 - t2     0.431 0.659 27   0.653  0.7923\n t1 - t3     4.952 0.350 27  14.138  &lt;.0001\n t2 - t3     4.521 0.677 27   6.676  &lt;.0001\n\ngroup = B:\n contrast estimate    SE df t.ratio p.value\n t1 - t2     1.226 0.659 27   1.859  0.1700\n t1 - t3     5.572 0.350 27  15.908  &lt;.0001\n t2 - t3     4.345 0.677 27   6.417  &lt;.0001\n\ngroup = C:\n contrast estimate    SE df t.ratio p.value\n t1 - t2     0.132 0.659 27   0.200  0.9781\n t1 - t3     4.262 0.350 27  12.170  &lt;.0001\n t2 - t3     4.130 0.677 27   6.099  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\nShow the code# 使用 car::Anova 进行多变量检验\nanova_results &lt;- Anova(lm_aov2, idata = data.frame(time = factor(c(\"t1\", \"t2\", \"t3\"))), idesign = ~time, type = \"III\")\n\nsummary(anova_results, multivariate = TRUE)  # 查看多变量检验结果\n\n\nType III Repeated Measures MANOVA Tests:\n\n------------------------------------------\n \nTerm: (Intercept) \n\n Response transformation matrix:\n   (Intercept)\nt1           1\nt2           1\nt3           1\n\nSum of squares and products for the hypothesis:\n            (Intercept)\n(Intercept)    10084.06\n\nMultivariate Tests: (Intercept)\n                 Df test stat approx F num Df den Df     Pr(&gt;F)    \nPillai            1   0.99047 2804.768      1     27 &lt; 2.22e-16 ***\nWilks             1   0.00953 2804.768      1     27 &lt; 2.22e-16 ***\nHotelling-Lawley  1 103.88030 2804.768      1     27 &lt; 2.22e-16 ***\nRoy               1 103.88030 2804.768      1     27 &lt; 2.22e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------\n \nTerm: group \n\n Response transformation matrix:\n   (Intercept)\nt1           1\nt2           1\nt3           1\n\nSum of squares and products for the hypothesis:\n            (Intercept)\n(Intercept)    5.136233\n\nMultivariate Tests: group\n                 Df test stat  approx F num Df den Df  Pr(&gt;F)\nPillai            2 0.0502517 0.7142929      2     27 0.49856\nWilks             2 0.9497483 0.7142929      2     27 0.49856\nHotelling-Lawley  2 0.0529106 0.7142929      2     27 0.49856\nRoy               2 0.0529106 0.7142929      2     27 0.49856\n\n------------------------------------------\n \nTerm: time \n\n Response transformation matrix:\n   time1 time2\nt1     1     0\nt2     0     1\nt3    -1    -1\n\nSum of squares and products for the hypothesis:\n         time1    time2\ntime1 728.6962 640.5426\ntime2 640.5426 563.0533\n\nMultivariate Tests: time\n                 Df test stat approx F num Df den Df     Pr(&gt;F)    \nPillai            1  0.957481 292.7437      2     26 &lt; 2.22e-16 ***\nWilks             1  0.042519 292.7437      2     26 &lt; 2.22e-16 ***\nHotelling-Lawley  1 22.518744 292.7437      2     26 &lt; 2.22e-16 ***\nRoy               1 22.518744 292.7437      2     26 &lt; 2.22e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n------------------------------------------\n \nTerm: group:time \n\n Response transformation matrix:\n   time1 time2\nt1     1     0\nt2     0     1\nt3    -1    -1\n\nSum of squares and products for the hypothesis:\n         time1     time2\ntime1 8.577925 1.4740641\ntime2 1.474064 0.7659704\n\nMultivariate Tests: group:time\n                 Df test stat approx F num Df den Df   Pr(&gt;F)  \nPillai            2 0.2188202 1.658492      4     54 0.173119  \nWilks             2 0.7821070 1.699761      4     52 0.164141  \nHotelling-Lawley  2 0.2774120 1.733825      4     50 0.157273  \nRoy               2 0.2730708 3.686456      2     27 0.038414 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n            Sum Sq num Df Error SS den Df   F value Pr(&gt;F)    \n(Intercept) 3361.4      1   32.358     27 2804.7682 &lt;2e-16 ***\ngroup          1.7      2   32.358     27    0.7143 0.4986    \ntime         434.1      2   91.436     54  128.1956 &lt;2e-16 ***\ngroup:time     5.2      4   91.436     54    0.7746 0.5465    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMauchly Tests for Sphericity\n\n           Test statistic   p-value\ntime               0.5916 0.0010873\ngroup:time         0.5916 0.0010873\n\n\nGreenhouse-Geisser and Huynh-Feldt Corrections\n for Departure from Sphericity\n\n            GG eps Pr(&gt;F[GG])    \ntime       0.71002  9.551e-16 ***\ngroup:time 0.71002      0.509    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n              HF eps   Pr(&gt;F[HF])\ntime       0.7381052 2.805049e-16\ngroup:time 0.7381052 5.132499e-01"
  },
  {
    "objectID": "posts/Software/Zotero.html",
    "href": "posts/Software/Zotero.html",
    "title": "Zotero",
    "section": "",
    "text": "Zotero 7\nhttps://zotero-zh.netlify.app/user-guide/plugins/style"
  },
  {
    "objectID": "posts/Software/Zotero.html#标题进度条",
    "href": "posts/Software/Zotero.html#标题进度条",
    "title": "Zotero",
    "section": "标题进度条",
    "text": "标题进度条\n在标题列上右击，选择列设置（标题），进入设置窗口。\nColor: 颜色 Opacity: 透明度"
  },
  {
    "objectID": "posts/Software/Zotero.html#期刊标签",
    "href": "posts/Software/Zotero.html#期刊标签",
    "title": "Zotero",
    "section": "期刊标签",
    "text": "期刊标签\n\neasyScholar 密钥\n密钥申请：在 easyScholar 官网首页登录后，点击右上角用户名进入后台，点击 「开放接口」，即可看见密钥。\n期刊标签\n密钥填写：直接填写到上方 Secret Key 里。"
  },
  {
    "objectID": "posts/Software/Zotero.html#标注",
    "href": "posts/Software/Zotero.html#标注",
    "title": "Zotero",
    "section": "标注",
    "text": "标注\n通过Shift+P，点标注进入标注的自定义列表。\n左键单击：切换不同的标注方案\n左键单击方案名称：修改方案名称\n长按：修改已有标注。\n点击+：添加新的标注方案。\n长按颜色区域：删除标注方案"
  },
  {
    "objectID": "posts/PropensityScore/psm.html",
    "href": "posts/PropensityScore/psm.html",
    "title": "Propensity score matching",
    "section": "",
    "text": "Propensity score matching (Nature Methods)"
  },
  {
    "objectID": "posts/MetaAnalysis/pooling_effect_sizes.html",
    "href": "posts/MetaAnalysis/pooling_effect_sizes.html",
    "title": "pooling effect sizes",
    "section": "",
    "text": "聚合效应大小\nShow the codedevtools::install_github(\"MathiasHarrer/dmetar\")"
  },
  {
    "objectID": "posts/MetaAnalysis/pooling_effect_sizes.html#固定效应模型",
    "href": "posts/MetaAnalysis/pooling_effect_sizes.html#固定效应模型",
    "title": "pooling effect sizes",
    "section": "固定效应模型",
    "text": "固定效应模型\n\\[\n\\hat\\theta_k = \\theta + \\epsilon_k\n\\]\n当我们在荟萃分析中汇总效应时，我们应该给精度更高（即标准误差更小）的效应大小赋予更大的权重。如果我们想计算固定效应模型下的合并效应大小，那么我们只需使用所有研究的加权平均值。\n对于每一项研究k，计算其权重\n\\[\nw_k = \\frac{1}{s^2_k}\n\\]\n\nK项研究真实总体效应的最佳估计值：逆方差加权\n\\[\n\\hat\\theta = \\frac{\\sum^{K}_{k=1} \\hat\\theta_kw_k}{\\sum^{K}_{k=1} w_k}\n\\]\n\nShow the codelibrary(dmetar)\nlibrary(meta)\ndata(SuicidePrevention)\n# Calculate Hedges' g and the Standard Error\n# - We save the study names in \"study\".\n# - We use the pmap_dfr function to calculate the effect size for each row.\nSP_calc &lt;- pmap_dfr(SuicidePrevention, \n                    function(mean.e, sd.e, n.e, mean.c,\n                             sd.c, n.c, author, ...){\n                      esc::esc_mean_sd(grp1m = mean.e,\n                                  grp1sd = sd.e,\n                                  grp1n = n.e,\n                                  grp2m = mean.c,\n                                  grp2sd = sd.c,\n                                  grp2n = n.c,\n                                  study = author,\n                                  es.type = \"g\") %&gt;% \n                        as.data.frame()}) \n\nglimpse(SP_calc)\n\nRows: 9\nColumns: 9\n$ study       &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt …\n$ es          &lt;dbl&gt; -0.14279447, -0.60770928, -0.11117965, -0.12698011, -0.392…\n$ weight      &lt;dbl&gt; 46.09784, 34.77314, 14.97625, 32.18243, 24.52054, 54.50431…\n$ sample.size &lt;dbl&gt; 185, 146, 60, 129, 100, 220, 120, 80, 107\n$ se          &lt;dbl&gt; 0.1472854, 0.1695813, 0.2584036, 0.1762749, 0.2019459, 0.1…\n$ var         &lt;dbl&gt; 0.02169299, 0.02875783, 0.06677240, 0.03107286, 0.04078214…\n$ ci.lo       &lt;dbl&gt; -0.4314686, -0.9400826, -0.6176413, -0.4724727, -0.7882811…\n$ ci.hi       &lt;dbl&gt; 0.145879624, -0.275335960, 0.395282029, 0.218512440, 0.003…\n$ measure     &lt;chr&gt; \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\"\n\n\n\nShow the code# Calculate the inverse variance-weights for each study\nSP_calc$w &lt;- 1/SP_calc$se^2\n\n# Then, we use the weights to calculate the pooled effect\npooled_effect &lt;- sum(SP_calc$w*SP_calc$es)/sum(SP_calc$w)\npooled_effect\n\n[1] -0.2311121"
  },
  {
    "objectID": "posts/MetaAnalysis/pooling_effect_sizes.html#随机效应模型",
    "href": "posts/MetaAnalysis/pooling_effect_sizes.html#随机效应模型",
    "title": "pooling effect sizes",
    "section": "随机效应模型",
    "text": "随机效应模型\n\\[\n\\theta_k  = \\mu + \\zeta_k\n\\]\n\\[\n\\hat\\theta_k = \\mu + \\zeta_k + \\epsilon_k\n\\]\n随机效应模型的可交换性假设：研究间异质性 \\(\\zeta_k\\) 与k独立\n\\[\nw^*_k = \\frac{1}{s^2_k+\\tau^2}\n\\]\n\\[\n\\hat\\theta = \\frac{\\sum^{K}_{k=1} \\hat\\theta_kw^*_k}{\\sum^{K}_{k=1} w^*_k}\n\\]\n研究间异质性：异质性方差 \\(\\tau^2\\) 估计方法\n\n对于基于连续结局数据的效应量，可以使用限制最大似然估计量作为第一个开始。\n对于二元效应大小数据，Paule-Mandel 估计量是不错的首选，前提是样本大小没有极端变化。\n当您有充分的理由相信样本中效应的异质性非常大，并且避免假阳性具有非常高的优先级时，您可以使用 Sidik-Jonkman 估计器。\n如果您希望其他人可以在 R 之外尽可能精确地复制您的结果，那么 DerSimonian-Laird 估计器是首选方法。Cochran’s Q\n\nKnapp-Hartung 调整\n合并效应的显著性检验通常假定正态分布（所谓的 Wald 型检验）\n但 Knapp-Hartung 方法基于t分布，Knapp-Hartung 调整只能在随机效应模型中使用，并且通常会导致合并效应的置信区间略大。"
  },
  {
    "objectID": "posts/MetaAnalysis/pooling_effect_sizes.html#效应值数据",
    "href": "posts/MetaAnalysis/pooling_effect_sizes.html#效应值数据",
    "title": "pooling effect sizes",
    "section": "效应值数据",
    "text": "效应值数据\n\nPre-calculated\n\nShow the codedata(ThirdWave)\nglimpse(ThirdWave)\n\nRows: 18\nColumns: 8\n$ Author               &lt;chr&gt; \"Call et al.\", \"Cavanagh et al.\", \"DanitzOrsillo\"…\n$ TE                   &lt;dbl&gt; 0.7091362, 0.3548641, 1.7911700, 0.1824552, 0.421…\n$ seTE                 &lt;dbl&gt; 0.2608202, 0.1963624, 0.3455692, 0.1177874, 0.144…\n$ RiskOfBias           &lt;chr&gt; \"high\", \"low\", \"high\", \"low\", \"low\", \"low\", \"high…\n$ TypeControlGroup     &lt;chr&gt; \"WLC\", \"WLC\", \"WLC\", \"no intervention\", \"informat…\n$ InterventionDuration &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"sho…\n$ InterventionType     &lt;chr&gt; \"mindfulness\", \"mindfulness\", \"ACT\", \"mindfulness…\n$ ModeOfDelivery       &lt;chr&gt; \"group\", \"online\", \"group\", \"group\", \"online\", \"g…\n\n\n\nShow the codelibrary(meta)\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 title = \"Third Wave Psychotherapies\")\nsummary(m.gen)\n\nReview:     Third Wave Psychotherapies\n\n                          SMD            95%-CI %W(random)\nCall et al.            0.7091 [ 0.1979; 1.2203]        5.0\nCavanagh et al.        0.3549 [-0.0300; 0.7397]        6.3\nDanitzOrsillo          1.7912 [ 1.1139; 2.4685]        3.8\nde Vibe et al.         0.1825 [-0.0484; 0.4133]        7.9\nFrazier et al.         0.4219 [ 0.1380; 0.7057]        7.3\nFrogeli et al.         0.6300 [ 0.2458; 1.0142]        6.3\nGallego et al.         0.7249 [ 0.2846; 1.1652]        5.7\nHazlett-Stevens & Oren 0.5287 [ 0.1162; 0.9412]        6.0\nHintz et al.           0.2840 [-0.0453; 0.6133]        6.9\nKang et al.            1.2751 [ 0.6142; 1.9360]        3.9\nKuhlmann et al.        0.1036 [-0.2781; 0.4853]        6.3\nLever Taylor et al.    0.3884 [-0.0639; 0.8407]        5.6\nPhang et al.           0.5407 [ 0.0619; 1.0196]        5.3\nRasanen et al.         0.4262 [-0.0794; 0.9317]        5.1\nRatanasiripong         0.5154 [-0.1731; 1.2039]        3.7\nShapiro et al.         1.4797 [ 0.8618; 2.0977]        4.2\nSong & Lindquist       0.6126 [ 0.1683; 1.0569]        5.7\nWarnecke et al.        0.6000 [ 0.1120; 1.0880]        5.2\n\nNumber of studies: k = 18\n\n                             SMD           95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [0.3782; 0.7760] 6.12 &lt; 0.0001\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 17)\n\n\n\n第一部分包含各个研究，以及它们的效应值和置信区间\n研究总数\n随机效应模型效果大小：Knapp-Hartung 调整 t分布,估计值g≈0.58，并且 95% 置信区间范围为0.38 至 0.78。 ，\n研究间异质性：Quantifying heterogeneity τ2=0.08（0.03-0.35） ,置信区间不包含零，表明我们的数据中存在一些研究间异质性。 \\(\\tau\\)=0.29表示真实的效应大小具有估计的标准偏差SD=0.29，以效应大小度量的尺度表示（这里为Hedges’g）。I2=63%，H（H2的平方根）为1.64。这意味着，我们数据中超过一半的变化估计源于真实的效应大小差异\n\n所有这些都表明我们的数据中存在研究间异质性，随机效应模型是一个不错的选择。\n\n异质性检验：Q=45.5和Test of heterogeneity。K−1=17 个自由度。因此，异质性检验是显著的 （p&lt;0.001）\n连续\n（标准化）平均差\n\nShow the code# Load dataset from dmetar (or download and open manually)\ndata(SuicidePrevention)\n\n# Use metcont to pool results.\nm.cont &lt;- metacont(n.e = n.e,\n                   mean.e = mean.e,\n                   sd.e = sd.e,\n                   n.c = n.c,\n                   mean.c = mean.c,\n                   sd.c = sd.c,\n                   studlab = author,\n                   data = SuicidePrevention,\n                   sm = \"SMD\",\n                   method.smd = \"Hedges\",\n                   fixed = FALSE,\n                   random = TRUE,\n                   method.tau = \"REML\",\n                   method.random.ci = \"HK\",\n                   title = \"Suicide Prevention\")\nsummary(m.cont)\n\nReview:     Suicide Prevention\n\n                    SMD             95%-CI %W(random)\nBerry et al.    -0.1428 [-0.4315;  0.1459]       15.6\nDeVries et al.  -0.6077 [-0.9402; -0.2752]       12.3\nFleming et al.  -0.1112 [-0.6177;  0.3953]        5.7\nHunt & Burke    -0.1270 [-0.4725;  0.2185]       11.5\nMcCarthy et al. -0.3925 [-0.7884;  0.0034]        9.0\nMeijer et al.   -0.2676 [-0.5331; -0.0021]       17.9\nRivera et al.    0.0124 [-0.3454;  0.3703]       10.8\nWatkins et al.  -0.2448 [-0.6848;  0.1952]        7.4\nZaytsev et al.  -0.1265 [-0.5062;  0.2533]        9.7\n\nNumber of studies: k = 9\nNumber of observations: o = 1147 (o.e = 571, o.c = 576)\n\n                         SMD             95%-CI     t p-value\nRandom effects model -0.2304 [-0.3734; -0.0874] -3.71  0.0059\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0044 [0.0000; 0.0924]; tau = 0.0661 [0.0000; 0.3040]\n I^2 = 7.4% [0.0%; 67.4%]; H = 1.04 [1.00; 1.75]\n\nTest of heterogeneity:\n    Q d.f. p-value\n 8.64    8  0.3738\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 8)\n- Hedges' g (bias corrected standardised mean difference; using exact formulae)\n\n\n二分类\nmetabin()\nRR\n\nShow the codedata(DepressionMortality)\nglimpse(DepressionMortality)\n\nRows: 18\nColumns: 6\n$ author  &lt;chr&gt; \"Aaroma et al., 1994\", \"Black et al., 1998\", \"Bruce et al., 19…\n$ event.e &lt;dbl&gt; 25, 65, 5, 26, 32, 1, 24, 15, 15, 173, 37, 41, 29, 61, 15, 21,…\n$ n.e     &lt;dbl&gt; 215, 588, 46, 67, 407, 44, 60, 61, 29, 1015, 105, 120, 258, 38…\n$ event.c &lt;dbl&gt; 171, 120, 107, 1168, 269, 87, 200, 437, 227, 250, 66, 9, 24, 3…\n$ n.c     &lt;dbl&gt; 3088, 1901, 2479, 3493, 6256, 1520, 882, 2603, 853, 3375, 409,…\n$ country &lt;chr&gt; \"Finland\", \"USA\", \"USA\", \"USA\", \"Sweden\", \"USA\", \"Canada\", \"Ne…\n\nShow the codem.bin &lt;- metabin(event.e = event.e, \n                 n.e = n.e,\n                 event.c = event.c,\n                 n.c = n.c,\n                 studlab = author,\n                 data = DepressionMortality,\n                 sm = \"RR\",\n                 method = \"MH\",\n                 MH.exact = TRUE,\n                 fixed = TRUE,\n                 random = TRUE,\n                 method.tau = \"PM\",\n                 method.random.ci = \"HK\",\n                 title = \"Depression and Mortality\")\nsummary(m.bin)\n\nReview:     Depression and Mortality\n\n                          RR            95%-CI %W(common) %W(random)\nAaroma et al., 1994   2.0998 [1.4128;  3.1208]        4.6        6.0\nBlack et al., 1998    1.7512 [1.3139;  2.3341]       11.6        6.6\nBruce et al., 1989    2.5183 [1.0785;  5.8802]        0.8        3.7\nBruce et al., 1994    1.1605 [0.8560;  1.5733]        9.0        6.5\nEnzell et al., 1984   1.8285 [1.2853;  2.6014]        6.8        6.3\nFredman et al., 1989  0.3971 [0.0566;  2.7861]        1.0        1.2\nMurphy et al., 1987   1.7640 [1.2644;  2.4610]        5.2        6.4\nPenninx et al., 1999  1.4647 [0.9361;  2.2919]        4.1        5.8\nPulska et al., 1998   1.9436 [1.3441;  2.8107]        3.1        6.2\nRoberts et al., 1990  2.3010 [1.9206;  2.7567]       23.7        7.0\nSaz et al., 1999      2.1837 [1.5533;  3.0700]        5.5        6.3\nSharma et al., 1998   2.0500 [1.0744;  3.9114]        2.5        4.7\nTakeida et al., 1997  6.9784 [4.1303; 11.7902]        1.5        5.3\nTakeida et al., 1999  5.8124 [3.8816;  8.7035]        3.3        6.0\nThomas et al., 1992   1.3303 [0.7780;  2.2745]        4.0        5.3\nThomas et al., 1992   1.7722 [1.1073;  2.8363]        4.1        5.6\nWeissman et al., 1986 1.2500 [0.6678;  2.3398]        2.7        4.8\nZheng et al., 1997    1.9803 [1.4001;  2.8011]        6.4        6.3\n\nNumber of studies: k = 18\nNumber of observations: o = 94770 (o.e = 4514, o.c = 90256)\nNumber of events: e = 5439\n\n                         RR           95%-CI   z|t  p-value\nCommon effect model  2.0634 [1.8909; 2.2516] 16.26 &lt; 0.0001\nRandom effects model 2.0217 [1.5786; 2.5892]  6.00 &lt; 0.0001\n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.1865 [0.0739; 0.5568]; tau = 0.4319 [0.2718; 0.7462]\n I^2 = 77.2% [64.3%; 85.4%]; H = 2.09 [1.67; 2.62]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 74.49   17 &lt; 0.0001\n\nDetails of meta-analysis methods:\n- Mantel-Haenszel method (common effect model)\n- Inverse variance method (random effects model)\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 17)"
  },
  {
    "objectID": "posts/MetaAnalysis/forest_plots.html",
    "href": "posts/MetaAnalysis/forest_plots.html",
    "title": "森林图",
    "section": "",
    "text": "Show the codelibrary(meta)\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = dmetar::ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 prediction = TRUE,\n                 title = \"Third Wave Psychotherapies\")\n\n\n\nShow the codemeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"))\n\n\n\n\n\n\n\n\nShow the codemeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftcols = c(\"studlab\", \"TE\", \"seTE\", \"RiskOfBias\"),\n             leftlabs = c(\"Author\", \"g\", \"SE\", \"Risk of Bias\"))\n\n\n\n\n\n\n\n\nShow the codemeta::forest(m.gen, layout = \"JAMA\")\n\n\n\n\n\n\n\n\nShow the codemeta::forest(m.gen, layout = \"RevMan5\")\n\n\n\n\n\n\n\n\nShow the codepdf(file = \"images/forestplot.pdf\", width = 8, height = 7)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"))\n\ndev.off()\n\npng \n  2 \n\n\n\nShow the codesvg(file = \"images/forestplot.svg\", width = 8, height = 7)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"))\n\ndev.off()\n\npng \n  2"
  },
  {
    "objectID": "posts/MetaAnalysis/forest_plots.html#森林图",
    "href": "posts/MetaAnalysis/forest_plots.html#森林图",
    "title": "森林图",
    "section": "",
    "text": "Show the codelibrary(meta)\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = dmetar::ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 prediction = TRUE,\n                 title = \"Third Wave Psychotherapies\")\n\n\n\nShow the codemeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"))\n\n\n\n\n\n\n\n\nShow the codemeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftcols = c(\"studlab\", \"TE\", \"seTE\", \"RiskOfBias\"),\n             leftlabs = c(\"Author\", \"g\", \"SE\", \"Risk of Bias\"))\n\n\n\n\n\n\n\n\nShow the codemeta::forest(m.gen, layout = \"JAMA\")\n\n\n\n\n\n\n\n\nShow the codemeta::forest(m.gen, layout = \"RevMan5\")\n\n\n\n\n\n\n\n\nShow the codepdf(file = \"images/forestplot.pdf\", width = 8, height = 7)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"))\n\ndev.off()\n\npng \n  2 \n\n\n\nShow the codesvg(file = \"images/forestplot.svg\", width = 8, height = 7)\n\nmeta::forest(m.gen, \n             sortvar = TE,\n             prediction = TRUE, \n             print.tau2 = FALSE,\n             leftlabs = c(\"Author\", \"g\", \"SE\"))\n\ndev.off()\n\npng \n  2"
  },
  {
    "objectID": "posts/MetaAnalysis/forest_plots.html#drapery-plots",
    "href": "posts/MetaAnalysis/forest_plots.html#drapery-plots",
    "title": "森林图",
    "section": "Drapery Plots",
    "text": "Drapery Plots\n\nShow the codedrapery(m.gen, \n        labels = \"studlab\",\n        type = \"pval\", \n        legend = FALSE)"
  },
  {
    "objectID": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html",
    "href": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html",
    "title": "研究间异质性",
    "section": "",
    "text": "Between-Study Heterogeneity \\(\\zeta_k\\)"
  },
  {
    "objectID": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#cochrans-q",
    "href": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#cochrans-q",
    "title": "研究间异质性",
    "section": "Cochran’s Q",
    "text": "Cochran’s Q\nCochran’s Q定义为每一项研究与总体效应的偏差加权平方和 （weighted sum of squares, WSS）。\n\\[\nQ=\\sum_{k=1}^K \\omega_k(\\hat \\theta_k - \\hat\\theta)^2\n\\]\n当研究之间没有异质性即\\(\\zeta_k =0\\) 仅有抽样误差，假设\n\\[\n\\hat\\theta_k-\\hat\\theta\\sim N(0,1)\n\\]\n\nShow the codeset.seed(123) # needed to reproduce results\nrnorm(n = 40, mean = 0, sd = 1)\n\n [1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774  1.71506499\n [7]  0.46091621 -1.26506123 -0.68685285 -0.44566197  1.22408180  0.35981383\n[13]  0.40077145  0.11068272 -0.55584113  1.78691314  0.49785048 -1.96661716\n[19]  0.70135590 -0.47279141 -1.06782371 -0.21797491 -1.02600445 -0.72889123\n[25] -0.62503927 -1.68669331  0.83778704  0.15337312 -1.13813694  1.25381492\n[31]  0.42646422 -0.29507148  0.89512566  0.87813349  0.82158108  0.68864025\n[37]  0.55391765 -0.06191171 -0.30596266 -0.38047100\n\n\n\nShow the codeset.seed(123)\nerror_fixed &lt;- replicate(n = 10000, rnorm(40))\n\nhist(error_fixed, \n     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, \n     breaks = 100, ylim = c(0, .45), xlim = c(-4,4),\n     main = \"No Heterogeneity\")\nlines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), \n      col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n假设研究之间存在异质性 （\\(\\zeta_k\\)）和抽样误差（\\(\\epsilon_k\\)）\n\nShow the codeset.seed(123)\nerror_random &lt;- replicate(n = 10000, rnorm(40) + rnorm(40))\nhist(error_random, \n     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, \n     breaks = 100,ylim = c(0, .45), xlim = c(-4,4),\n     main = \"Heterogeneity\")\nlines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), \n      col = \"blue\", lwd = 2)\n\n\n\n\n\n\n\n计算Q，假设加权=1\n\nShow the codeset.seed(123)\nQ_fixed &lt;- replicate(10000, sum(rnorm(40)^2))\nQ_random &lt;- replicate(10000, sum((rnorm(40) + rnorm(40))^2))\n\n\n自由度为K−1的卡方分布（其中K是我们荟萃分析中的研究数量）\n\nShow the codedf &lt;- 40-1\n\nhist(Q_fixed, xlab = expression(italic(\"Q\")), prob = TRUE, \n     breaks = 100, ylim = c(0, .06),xlim = c(0,160),\n     main = \"No Heterogeneity\")\nlines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), \n      col = \"blue\", lwd = 2)\n\n\n\n\n\n\nShow the codehist(Q_random,  xlab = expression(italic(\"Q\")), prob = TRUE, \n     breaks = 100, ylim = c(0, .06), xlim = c(0,160),\n     main = \"Heterogeneity\")\nlines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), \n      col = \"blue\", lwd = 2)"
  },
  {
    "objectID": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#higgins-thompsons-i2statistic",
    "href": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#higgins-thompsons-i2statistic",
    "title": "研究间异质性",
    "section": "\nHiggins & Thompson’s \\(I^2\\)Statistic",
    "text": "Higgins & Thompson’s \\(I^2\\)Statistic\n\\(I^2\\) 是另一种估计异质性的方法，基于Cochran’s Q。 它被定义为不是由抽样误差引起的效应量的变异百分比\n\\(I^2\\) 基于以下假设：在无异质性的零假设下，Q遵循具有K-1自由度的χ2分布。它以百分比的形式量化了在没有异质性（即K-1）的情况下，观察到的Q值超过预期Q值的程度。\n\\[\nI^2=\\frac{Q-(K-1)}{Q}\n\\]\nI2的值不能低于0%，因此如果Q恰好小于K-1，我们只需使用0而不是负值\n\nShow the code# Display the value of the 10th simulation of Q\nQ_fixed[10]\n\n[1] 35.85787\n\nShow the code# Define k\nk &lt;- 40\n\n# Calculate I^2\n(Q_fixed[10] - (k-1))/Q_fixed[10]\n\n[1] -0.08762746\n\n\n\\(I^2\\) = 0% 说明效应量的0%是由研究间的异质性引起的\n\nShow the code(Q_random[10] - (k-1))/Q_random[10]\n\n[1] 0.5692061\n\n\n大约一半的差异是由于研究之间的异质性造成的。这也符合我们的预期，因为此示例中的变异同等程度地基于模拟的抽样误差和研究之间的异质性。\n\nI2 = 25%: low heterogeneity\nI2 = 50%: moderate heterogeneity\nI2 = 75%: substantial heterogeneity."
  },
  {
    "objectID": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#h2-statistic",
    "href": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#h2-statistic",
    "title": "研究间异质性",
    "section": "\n\\(H^2\\) statistic",
    "text": "\\(H^2\\) statistic\n它描述了由Q测量的观察到的变化与由于采样误差引起的预期变化的比率\n\\[\nH^2=\\frac{Q}{K-1}\n\\]\n当研究之间没有异质性时，H2等于1（或更小）。大于1的值表示研究之间存在异质性。"
  },
  {
    "objectID": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#heterogeneity-variance-tau2-standard-deviation-tau",
    "href": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#heterogeneity-variance-tau2-standard-deviation-tau",
    "title": "研究间异质性",
    "section": "\nHeterogeneity Variance \\(\\tau^2\\)& Standard Deviation \\(\\tau\\)\n",
    "text": "Heterogeneity Variance \\(\\tau^2\\)& Standard Deviation \\(\\tau\\)\n\n\nShow the codelibrary(meta)\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = dmetar::ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 title = \"Third Wave Psychotherapies\")\n\n\n\nShow the code# Pooled effect\nm.gen$TE.random\n\n[1] 0.5771158\n\nShow the code# Estimate of tau\nm.gen$tau\n\n[1] 0.2863311\n\n\n我们看到了g=0.58 和τ=0.29. 根据这些数据，我们可以计算出 95% 真实效应量置信区间的下限和上限：0.58−1.96×0.29 = 0.01 和 0.58 1.96+×0.29 = 1.15。"
  },
  {
    "objectID": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#prediction-intervals-pis",
    "href": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#prediction-intervals-pis",
    "title": "研究间异质性",
    "section": "Prediction intervals (PIs) ",
    "text": "Prediction intervals (PIs) \n95% 预测区间的公式如下所示：\n\n\n\n\n\nShow the codem.gen &lt;- update(m.gen, prediction = TRUE)\nsummary(m.gen)\n\nReview:     Third Wave Psychotherapies\n\n                          SMD            95%-CI %W(random)\nCall et al.            0.7091 [ 0.1979; 1.2203]        5.0\nCavanagh et al.        0.3549 [-0.0300; 0.7397]        6.3\nDanitzOrsillo          1.7912 [ 1.1139; 2.4685]        3.8\nde Vibe et al.         0.1825 [-0.0484; 0.4133]        7.9\nFrazier et al.         0.4219 [ 0.1380; 0.7057]        7.3\nFrogeli et al.         0.6300 [ 0.2458; 1.0142]        6.3\nGallego et al.         0.7249 [ 0.2846; 1.1652]        5.7\nHazlett-Stevens & Oren 0.5287 [ 0.1162; 0.9412]        6.0\nHintz et al.           0.2840 [-0.0453; 0.6133]        6.9\nKang et al.            1.2751 [ 0.6142; 1.9360]        3.9\nKuhlmann et al.        0.1036 [-0.2781; 0.4853]        6.3\nLever Taylor et al.    0.3884 [-0.0639; 0.8407]        5.6\nPhang et al.           0.5407 [ 0.0619; 1.0196]        5.3\nRasanen et al.         0.4262 [-0.0794; 0.9317]        5.1\nRatanasiripong         0.5154 [-0.1731; 1.2039]        3.7\nShapiro et al.         1.4797 [ 0.8618; 2.0977]        4.2\nSong & Lindquist       0.6126 [ 0.1683; 1.0569]        5.7\nWarnecke et al.        0.6000 [ 0.1120; 1.0880]        5.2\n\nNumber of studies: k = 18\n\n                             SMD            95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [ 0.3782; 0.7760] 6.12 &lt; 0.0001\nPrediction interval              [-0.0542; 1.2084]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 17)\n- Prediction interval based on t-distribution (df = 17)\n\n\n在合并效应的直接作用下，我们看到了预测区间。其范围为g=-0.06至1.21。这意味着，根据目前的证据，未来的一些研究可能会发现负面的治疗效果。然而，间隔相当宽，这意味着也可能产生非常高的效果。"
  },
  {
    "objectID": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#异常值",
    "href": "posts/MetaAnalysis/BetweenStudyHeterogeneity.html#异常值",
    "title": "研究间异质性",
    "section": "异常值",
    "text": "异常值\n删除\n\nShow the codedmetar::find.outliers(m.gen)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"DanitzOrsillo\", \"Shapiro et al.\" \n \nResults with outliers removed \n----------------------------- \nReview:     Third Wave Psychotherapies\n\nNumber of studies: k = 16\n\n                             SMD           95%-CI    t  p-value\nRandom effects model (HK) 0.4528 [0.3257; 0.5800] 7.59 &lt; 0.0001\nPrediction interval              [0.1705; 0.7352]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0139 [0.0000; 0.1032]; tau = 0.1180 [0.0000; 0.3213]\n I^2 = 24.8% [0.0%; 58.7%]; H = 1.15 [1.00; 1.56]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 19.95   15  0.1739\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 15)\n- Prediction interval based on t-distribution (df = 15)\n\n\n影响分析\n\nShow the codem.gen.inf &lt;- dmetar::InfluenceAnalysis(m.gen, random = TRUE)\n\n[===========================================================================] DONE \n\n\n\nShow the codeplot(m.gen.inf, \"baujat\")\n\n\n\n\n\n\n\n\nShow the codeplot(m.gen.inf, \"influence\")\n\n\n\n\n\n\n\n\nShow the codeplot(m.gen.inf, \"es\")\n\n\n\n\n\n\nShow the codeplot(m.gen.inf, \"i2\")\n\n\n\n\n\n\n\nGOSH Plot Analysis\nGraphic Display of Heterogeneity (GOSH) \n\nShow the codelibrary(metafor)\n\nm.rma &lt;- rma(yi = m.gen$TE,\n             sei = m.gen$seTE,\n             method = m.gen$method.tau,\n             test = \"knha\")\n\n\n\nShow the coderes.gosh &lt;- gosh(m.rma)\nsave(res.gosh,file = \"data/res.gosh.RData\")\n\n\n\nShow the codeload(\"data/res.gosh.RData\")\nplot(res.gosh, alpha = 0.01)\n\n\n\n\n\n\n\nGOSH 诊断图\n\nShow the code#' @usage gosh.diagnostics(data, km = TRUE, db = TRUE, gmm = TRUE,\n#'                  km.params = list(centers = 3,\n#'                                   iter.max = 10, nstart = 1,\n#'                                   algorithm = c(\"Hartigan-Wong\",\n#'                                   \"Lloyd\", \"Forgy\",\"MacQueen\"),\n#'                                   trace = FALSE),\n#'                  db.params = list(eps = 0.15, MinPts = 5,\n#'                                   method = c(\"hybrid\", \"raw\", \"dist\")),\n#'                  gmm.params = list(G = NULL, modelNames = NULL,\n#'                                    prior = NULL, control = emControl(),\n#'                                    initialization = list(hcPairs = NULL,\n#'                                    subset = NULL,\n#'                                    noise = NULL),\n#'                                    Vinv = NULL,\n#'                                    warn = mclust.options(\"warn\"),\n#'                                    x = NULL, verbose = FALSE),\n#'                  seed = 123,\n#'                  verbose = TRUE)\n\n\n\nShow the coderes.gosh.diag &lt;- dmetar::gosh.diagnostics(res.gosh, \n                                  km.params = list(centers = 2),\n                                  db.params = list(eps = 0.08, \n                                                   MinPts = 50))\n\n\n\nShow the codedata(\"m.gosh\",package = \"dmetar\")\nres.diag &lt;-dmetar::gosh.diagnostics(m.gosh)\n\n  \n Perform Clustering... \n |==========================================================================================| DONE \n\nShow the coderes.diag \n\nGOSH Diagnostics \n================================ \n\n - Number of K-means clusters detected: 3\n - Number of DBSCAN clusters detected: 4\n - Number of GMM clusters detected: 4\n\n Identification of potential outliers \n --------------------------------- \n\n - K-means: Study 3, Study 4\n - DBSCAN: Study 3, Study 4\n - Gaussian Mixture Model: Study 3\n\nShow the codeplot(res.diag)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the codeupdate(m.gen, exclude = c(3, 4, 16)) %&gt;% \n  summary()\n\nReview:     Third Wave Psychotherapies\n\n                          SMD            95%-CI %W(random) exclude\nCall et al.            0.7091 [ 0.1979; 1.2203]        4.6        \nCavanagh et al.        0.3549 [-0.0300; 0.7397]        8.1        \nDanitzOrsillo          1.7912 [ 1.1139; 2.4685]        0.0       *\nde Vibe et al.         0.1825 [-0.0484; 0.4133]        0.0       *\nFrazier et al.         0.4219 [ 0.1380; 0.7057]       14.8        \nFrogeli et al.         0.6300 [ 0.2458; 1.0142]        8.1        \nGallego et al.         0.7249 [ 0.2846; 1.1652]        6.2        \nHazlett-Stevens & Oren 0.5287 [ 0.1162; 0.9412]        7.0        \nHintz et al.           0.2840 [-0.0453; 0.6133]       11.0        \nKang et al.            1.2751 [ 0.6142; 1.9360]        2.7        \nKuhlmann et al.        0.1036 [-0.2781; 0.4853]        8.2        \nLever Taylor et al.    0.3884 [-0.0639; 0.8407]        5.8        \nPhang et al.           0.5407 [ 0.0619; 1.0196]        5.2        \nRasanen et al.         0.4262 [-0.0794; 0.9317]        4.7        \nRatanasiripong         0.5154 [-0.1731; 1.2039]        2.5        \nShapiro et al.         1.4797 [ 0.8618; 2.0977]        0.0       *\nSong & Lindquist       0.6126 [ 0.1683; 1.0569]        6.1        \nWarnecke et al.        0.6000 [ 0.1120; 1.0880]        5.0        \n\nNumber of studies: k = 15\n\n                             SMD           95%-CI    t  p-value\nRandom effects model (HK) 0.4819 [0.3595; 0.6043] 8.44 &lt; 0.0001\nPrediction interval              [0.3623; 0.6016]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 &lt; 0.0001 [0.0000; 0.0955]; tau = 0.0012 [0.0000; 0.3091]\n I^2 = 4.6% [0.0%; 55.7%]; H = 1.02 [1.00; 1.50]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 14.67   14  0.4011\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 14)\n- Prediction interval based on t-distribution (df = 14)"
  },
  {
    "objectID": "posts/literature_retrieval/PubMed.html",
    "href": "posts/literature_retrieval/PubMed.html",
    "title": "PubMed retrieval",
    "section": "",
    "text": "AND\nOR\nNOT"
  },
  {
    "objectID": "posts/literature_retrieval/PubMed.html#布尔逻辑检索",
    "href": "posts/literature_retrieval/PubMed.html#布尔逻辑检索",
    "title": "PubMed retrieval",
    "section": "",
    "text": "AND\nOR\nNOT"
  },
  {
    "objectID": "posts/literature_retrieval/PubMed.html#截断和通配符",
    "href": "posts/literature_retrieval/PubMed.html#截断和通配符",
    "title": "PubMed retrieval",
    "section": "截断和通配符",
    "text": "截断和通配符\n\n通配符wildcard randomi?ed (randomised, randomized)\n截断（*） 可替代 0 个或多个字符\n\n\n\n\n检索词\n结果 2024-10-15\n\n\n\n\nOsteoarthr*[Title/Abstract]\n104,730\n\n\nOsteoarthrosis[Title/Abstract]\n3,585\n\n\nosteoarthritis[Title/Abstract]\n95,813\n\n\nOsteoarthritides[Title/Abstract]\n5"
  },
  {
    "objectID": "posts/literature_retrieval/PubMed.html#filter",
    "href": "posts/literature_retrieval/PubMed.html#filter",
    "title": "PubMed retrieval",
    "section": "Filter",
    "text": "Filter\n“Clinical Trial” [Publication Type]\n“Randomized Controlled Trial” [Publication Type]"
  },
  {
    "objectID": "posts/literature_retrieval/PubMed.html#msh",
    "href": "posts/literature_retrieval/PubMed.html#msh",
    "title": "PubMed retrieval",
    "section": "MSH",
    "text": "MSH\nMeSH (Medical Subject Headings)\n主题词 + 自由词\n\n\n\n主题词\n自由词\n\n\n\n\nImmune Checkpoint Inhibitors\n\n\n\nRadiotherapy\n\n\n\nsmall cell lung carcinoma\n\n\n\ndrug treatment"
  },
  {
    "objectID": "posts/literature_retrieval/PubMed.html#数据库",
    "href": "posts/literature_retrieval/PubMed.html#数据库",
    "title": "PubMed retrieval",
    "section": "数据库",
    "text": "数据库\n\nPubMed\n\n\nCochrane Central Register of Controlled Trials， CENTRAL\n\n\nEmbase"
  },
  {
    "objectID": "posts/Language/English.html",
    "href": "posts/Language/English.html",
    "title": "English Notes",
    "section": "",
    "text": "意群分割：chunk by chunk\n\n名词短语\n动词短语\n介词短语\n从句\n\n\nretelling"
  },
  {
    "objectID": "posts/Graphics/ggpattern/ggpattern.html",
    "href": "posts/Graphics/ggpattern/ggpattern.html",
    "title": "ggpattern: ggplot2 with geometric texture amd images",
    "section": "",
    "text": "ggpattern 填充几何纹理或图像"
  },
  {
    "objectID": "posts/Graphics/ggpattern/ggpattern.html#先决条件",
    "href": "posts/Graphics/ggpattern/ggpattern.html#先决条件",
    "title": "ggpattern: ggplot2 with geometric texture amd images",
    "section": "先决条件",
    "text": "先决条件\n\nShow the codelibrary(ggforce)\nlibrary(patchwork)\nif(!require(ggpattern)) \n    install.packages(\"ggpattern\")\nlibrary(ggpattern)\n\nif(!require(gridpattern)) \n    install.packages(\"gridpattern\")\nlibrary(gridpattern)\nif(!require(ggh4x)) \n    install.packages(\"ggh4x\")\nlibrary(ggh4x)\n\n\n\nShow the codeset.seed(123)\ndf &lt;- tibble(\n    group = letters[1:5],\n    value = round(runif(5,min = 10,max = 100),digits = 0)\n)\n\ndf %&gt;% \n    ggplot(mapping = aes(x = group, y = value, fill = group)) +\n    geom_col()"
  },
  {
    "objectID": "posts/Graphics/ggpattern/ggpattern.html#ggpattern",
    "href": "posts/Graphics/ggpattern/ggpattern.html#ggpattern",
    "title": "ggpattern: ggplot2 with geometric texture amd images",
    "section": "ggpattern",
    "text": "ggpattern\n几何纹理\n\nShow the codenames_magick_stripe\n\n [1] \"crosshatch\"    \"crosshatch30\"  \"crosshatch45\"  \"horizontal\"   \n [5] \"horizontal2\"   \"horizontal3\"   \"hs_bdiagonal\"  \"hs_cross\"     \n [9] \"hs_diagcross\"  \"hs_fdiagonal\"  \"hs_horizontal\" \"hs_vertical\"  \n[13] \"left30\"        \"left45\"        \"right30\"       \"right45\"      \n[17] \"vertical\"      \"vertical2\"     \"vertical3\"    \n\nShow the codenames_hex\n\n[1] \"hex\"      \"hex1\"     \"hex2\"     \"hex3\"     \"hex_skew\"\n\nShow the codenames_pattern\n\n [1] \"ambient\"         \"circle\"          \"crosshatch\"      \"fill\"           \n [5] \"gradient\"        \"image\"           \"magick\"          \"none\"           \n [9] \"pch\"             \"placeholder\"     \"plasma\"          \"polygon_tiling\" \n[13] \"regular_polygon\" \"rose\"            \"stripe\"          \"text\"           \n[17] \"wave\"            \"weave\"          \n\n\n 'stripe' (default), 'crosshatch', 'pch', 'circle', 'none'\n\nShow the codep1 &lt;- ggplot(df, aes(group, value )) +\n  geom_col_pattern(pattern = \"stripe\", \n                   fill= \"white\",  # 条形背景色 \n                   color=\"red\",    # 条形边框色\n                   pattern_fill = \"skyblue\", # 几何纹理填充色\n                   pattern_colour=\"darkgreen\",\n                   pattern_angle =30,    # 旋转角度\n                   pattern_linetype= 3 ,# 笔划stroke 线型\n                   pattern_size= 1.2,   #笔画线宽\n                   ) +\n    ggtitle(\"线条：stripe\")\n\np2 &lt;- ggplot(df, aes(group, value )) +\n  geom_col_pattern(pattern = \"crosshatch\", \n                   fill= \"white\",  # 条形背景色 \n                   color=\"red\",    # 条形边框色\n                   pattern_fill = \"red\", # 几何纹理填充色\n                   pattern_colour=\"green\",\n                   pattern_angle =30 ,  # 角度\n                   pattern_spacing= 0.2\n                   ) +\n    ggtitle(\"交叉平行线：crosshatch\")\n\n\np3 &lt;- ggplot(df, aes(group, value )) +\n  geom_col_pattern(pattern = \"pch\",\n                   fill= \"white\",  # 条形背景色 \n                   color=\"red\",    # 条形边框色\n                   pattern_colour=\"green\",\n                   pattern_angle =30,  \n                   pattern_density = 1,\n                   ) +\n    ggtitle(\"点：pch\")\n\np4 &lt;- ggplot(df, aes(group, value )) +\n  geom_col_pattern(pattern = \"circle\",\n                   fill= \"white\",  # 条形背景色 \n                   color=\"red\",    # 条形边框色\n                   pattern_colour=\"darkgreen\",\n                   pattern_fill = \"skyblue\",\n                   pattern_angle =30,   # 角度\n                   pattern_density = 1,\n                   pattern_spacing= 0.2, # 间距\n                   ) +\n    ggtitle(\"圈：circle\")\n\n(p1+p2)/(p3+p4)\n\n\n\n\n\n\n\n波浪图案\n\nShow the codex_hex &lt;- 0.5 + 0.5 * cos(seq(2 * pi / 4, by = 2 * pi / 6, length.out = 6))\ny_hex &lt;- 0.5 + 0.5 * sin(seq(2 * pi / 4, by = 2 * pi / 6, length.out = 6))\ngrid::grid.newpage()\nwave_sine &lt;- grid.pattern_wave(x_hex, y_hex, colour = \"black\", type = \"sine\",\n                  fill = c(\"red\", \"blue\"), density = 0.4,\n                  spacing = 0.15, angle = 0,\n                  amplitude = 0.05, frequency = 1 / 0.20)\n\n\n\n\n\n\nShow the code# zig-zag pattern is a wave of \"type = triangle\"\ngrid::grid.newpage()\nwave_triangle &lt;- grid.pattern_wave(x_hex, y_hex, colour = \"black\", \n                                   type = \"triangle\",\n                    fill = c(\"red\", \"blue\"), density = 0.4,\n                    spacing = 0.15, angle = 0, amplitude = 0.075)\n\n\n\n\n\n\n\n编织类型\npattern_type= ,\npattern_subtype=\n\nShow the codenames_weave\n\n [1] \"basket\"            \"matt\"              \"matt_irregular\"   \n [4] \"plain\"             \"rib_warp\"          \"satin\"            \n [7] \"twill\"             \"twill_elongated\"   \"twill_herringbone\"\n[10] \"twill_zigzag\"     \n\n\n\nShow the codeggplot(df, aes(group, value)) +\n  geom_col_pattern(\n    aes(pattern_fill2=group, pattern_type=group),\n    pattern = 'weave',\n    colour = 'black', \n    pattern_density = 1.0,\n    pattern_fill = 'grey',\n    pattern_key_scale_factor = 0.5,\n  ) +\n  theme_bw() +\n  labs(title = \"Some 'weave' types\") + \n  scale_pattern_type_manual(values=c('plain','matt', 'twill_herringbone',\n                                     \"twill_zigzag\",'satin')) +\n  theme(legend.key.size = unit(1.5, 'cm'))\n\n\n\n\n\n\n\n混合模式\n\nShow the codeggplot(df, aes(group, value)) +\n  geom_col_pattern(aes(fill=group, pattern=group, pattern_type=group),colour='black') + \n  theme_bw() +\n  labs(title = \"Use 'stripe' and 'weave' patterns\") + \n  theme(legend.key.size = unit(1.5, 'cm')) +\n  scale_pattern_manual(values=c('stripe', 'weave', 'weave','stripe', 'weave')) +\n  scale_pattern_type_manual(values=c(NA, 'basket', 'matt', NA, 'twill_elongated'))\n\n\n\n\n\n\n\n\nShow the codelibrary(ggplot2)\nlibrary(ggpattern)\nToothGrowth$dose &lt;- factor(ToothGrowth$dose)\nggplot(ToothGrowth, aes(dose)) +\n    geom_bar_pattern(\n        aes(\n            fill = dose,\n            pattern = dose,\n            pattern_type = dose\n        ),\n        pattern_frequency = 5,\n        colour = 'black'\n    ) +\n    theme_bw() +\n    labs(title = \"Use 'stripe' and 'wave' patterns\") +\n    theme(legend.key.size = unit(1.5, 'cm')) +\n    scale_pattern_manual(values = c('stripe', 'wave', 'wave')) +\n    scale_pattern_type_manual(values = c(NA, 'triangle', 'sine'))"
  },
  {
    "objectID": "posts/Graphics/ggpattern/ggpattern.html#ggpattern-ggh4x",
    "href": "posts/Graphics/ggpattern/ggpattern.html#ggpattern-ggh4x",
    "title": "ggpattern: ggplot2 with geometric texture amd images",
    "section": "ggpattern + ggh4x",
    "text": "ggpattern + ggh4x\n\nShow the codelibrary(tidyverse)\nlibrary(ggh4x)\nlibrary(ggpattern)\n\nset.seed(233)\ntable1 &lt;- tibble(\n  x=letters[1:4] %&gt;% rep(each=16,length.out=192),\n  y=abs(rnorm(192,50,10)),\n  f=LETTERS[1:4] %&gt;% rep(each=4,length.out=192),\n  g=\"g1\"\n)\ntable2 &lt;- tibble(\n  x=letters[1:4] %&gt;% rep(each=16,length.out=192),\n  y=abs(rnorm(192,50,10)) %&gt;% sort(),\n  f=LETTERS[1:4] %&gt;% rep(each=4,length.out=192),\n  g=\"g2\"\n)\ntable3 &lt;- tibble(\n  x=letters[1:4] %&gt;% rep(each=16,length.out=192),\n  y=abs(rnorm(192,50,10)),\n  f=LETTERS[1:4] %&gt;% rep(each=4,length.out=192),\n  g=\"g3\"\n)\n\ntableAll &lt;- bind_rows(table1,table2,table3)\n\np1 &lt;- tableAll %&gt;% ggplot(aes(interaction(x, g),y,pattern=f)) +\n  stat_summary(geom=GeomColPattern,\n               fun = mean,\n               position = position_dodge(width = 1.2),\n               pattern_spacing = 0.025,\n               fill = 'white', \n               colour = 'black',) + \n  stat_summary(geom=\"errorbar\",\n               fun.data = mean_se,\n               position = position_dodge(width = 1.2)) + \n  scale_x_manual(values = c(1:4+seq(0,1,length.out=4),6:9+1+seq(0,1,length.out=4),11:14+2+seq(0,1,length.out=4)),guide = guide_axis_nested()) +\n  scale_y_continuous(expand = expansion(mult = c(0,0)),\n                     breaks = seq(0,80,by=10),) +\n  labs(x=NULL,y=NULL,pattern=NULL) +\n  guides(pattern=guide_legend(nrow = 1)) +\n  coord_cartesian(ylim = c(0,70)) +\n  theme_classic() + \n  theme(legend.position = \"inside\",\n        legend.position.inside = c(.83,.95),\n        axis.ticks.length.x = unit(0,\"mm\"),\n        axis.ticks.length.y = unit(-1,\"mm\"),\n        ggh4x.axis.nestline = element_line(color=NA))\np1"
  },
  {
    "objectID": "posts/Graphics/ggforce/angle_rounded_barplot.html",
    "href": "posts/Graphics/ggforce/angle_rounded_barplot.html",
    "title": "ggforce: barplot with round angle",
    "section": "",
    "text": "圆角柱状图"
  },
  {
    "objectID": "posts/Graphics/ggforce/angle_rounded_barplot.html#先决条件",
    "href": "posts/Graphics/ggforce/angle_rounded_barplot.html#先决条件",
    "title": "ggforce: barplot with round angle",
    "section": "先决条件",
    "text": "先决条件\n\nShow the codeif(!require(ggforce)) install.packages(\"ggforce\")\nlibrary(ggforce)"
  },
  {
    "objectID": "posts/Graphics/ggforce/angle_rounded_barplot.html#geom_shape",
    "href": "posts/Graphics/ggforce/angle_rounded_barplot.html#geom_shape",
    "title": "ggforce: barplot with round angle",
    "section": "geom_shape()",
    "text": "geom_shape()\n连续X\n\nShow the codeshape &lt;- data.frame(\n  x = c(0.25, 0.75,0.75,0.25),\n  y = c(0, 0,1,1)\n)\n\nggplot(shape, aes(x = x, y = y)) +\n  #geom_polygon(fill = 'red') +\n  geom_shape(radius = unit(0.5, 'cm'))+\n    scale_x_continuous(breaks = seq(0,2,1), limits = c(0,2))\n\n\n\n\n\n\n\n分类X\n\nShow the codedf &lt;- data.frame(trt = c(\"a\", \"b\", \"c\"), outcome = c(2.3, 1.9, 3.2))\n\nwidth &lt;- .9\n\ndf &lt;- df |&gt;\n    mutate(trt = factor(trt)) |&gt;\n    dplyr::reframe(\n        data.frame(\n            x = rep(as.numeric(trt) + width / 2 * c(-1, 1), each = 2), # 指定条形图四个角的坐标\n            outcome = c(c(0, outcome), rev(c(0, outcome)))\n        ),\n        .by = trt\n    )\ndf\n\n   trt    x outcome\n1    a 0.55     0.0\n2    a 0.55     2.3\n3    a 1.45     2.3\n4    a 1.45     0.0\n5    b 1.55     0.0\n6    b 1.55     1.9\n7    b 2.45     1.9\n8    b 2.45     0.0\n9    c 2.55     0.0\n10   c 2.55     3.2\n11   c 3.45     3.2\n12   c 3.45     0.0\n\nShow the codeggplot(df, aes(x, outcome, fill = trt)) +\n    geom_shape(radius = .05)+\n    scale_x_continuous(breaks = 1:3,labels = c(\"a\",\"b\",\"c\"))+\n    theme(\n        axis.title.x = element_blank()\n    )\n\n\n\n\n\n\n\n\nShow the codelibrary(ggforce)\nggplot(iris, aes(Petal.Length, Petal.Width, colour = Species)) +\n  geom_point() +\n  facet_zoom(x = Species == \"versicolor\")"
  },
  {
    "objectID": "posts/Config/Rprofile.site.html",
    "href": "posts/Config/Rprofile.site.html",
    "title": "Rprofile.site",
    "section": "",
    "text": "language=en\n\n\nShow the codeoptions(\"timeout\")\noptions(timeout = 180)\n\n# set a CRAN mirror\ngetOption(\"repos\")\noptions(\"BioC_mirror\")\n\n# \"https://mirrors.ustc.edu.cn/CRAN/\"\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\noptions(BioC_mirror = \"https://mirrors.tuna.tsinghua.edu.cn/bioconductor\")\n\n.First &lt;- function() {\n  library(showtext, quietly = T)\n  # font_add(\"Times New Roman Regular\", \"C:/Windows/Fonts/times.ttf\")\n  # font_add(\"Times New Roman Bold\", \"C:/Windows/Fonts/timesbd.ttf\")\n  # font_add(\"Times New Roman Bold Italic\", \"C:/Windows/Fonts/timesbi.ttf\")\n  # font_add(\"Times New Roman Italic\", \"C:/Windows/Fonts/timesi.ttf\")\n  # font_add(\"黑体 常规\", \"C:/Windows/Fonts/simhei.ttf\")\n  # font_add(\"楷体 常规\", \"C:/Windows/Fonts/simkai.ttf\")\n  showtext_auto()\n  # library(data.table)\n  library(conflicted)\n  library(tidyverse)\n  library(patchwork)\n  # library(BiocManager)\n  library(readxl)\n  library(writexl)\n  conflicted::conflict_scout()\n  message(today())\n}\n\n\n.Last &lt;- function() {\n\n}\n\n\n如果希望永久删除安装路径，可以直接编辑R的环境配置文件（例如 .Renviron），去掉相应的路径条目，然后重启R使更改生效。\n\nShow the code# 更新 R Gui\n\n# installr::updateR()\n\ntools &lt;- c(\n  \"installr\", \"devtools\",\"remotes\",\"conflicted\", \"reticulate\", \"BiocManager\")\n\n\nneeded &lt;- c(\n  \"tidyverse\", \"tidymodels\", \"readxl\", \"writexl\",\"plotly\",\"survminer\",\n  \"ggsurvfit\",\"arrow\"\n)\n\n# remotes::install_github(\"jbryer/psa\", build_vignettes = TRUE, dependencies = \"Enhances\")\n\noptional &lt;- c(\n  \"ggpubr\",\"pROC\", \"ggprism\", \"ggpattern\", \n  \"pheatmap\", \"ggfortify\", \"ggrepel\", \"ggthemes\",\"ggcorrplot\", \"ggpmisc\", \n  \"ggraph\", \"tidygraph\", \"svglite\",\n  \n  \n  \"gt\", \"gtsummary\", \"tableone\", \"flextable\",\n)\n\n\nlapply(tools, require)\n\n\n\n\nShow the code.libPaths()\n\n#&gt; [1] \"C:/Users/DELL/AppData/Local/R/win-library/4.4\" \"D:/R-4.4.1/library\"  \n#.libPaths(c(\"/envs/新路径\", .libPaths()))\n\n\n\nShow the code.libPaths(.libPaths()[.libPaths() != \"C:/Users/DELL/AppData/Local/R/win-library/4.4\"])\n.libPaths()"
  },
  {
    "objectID": "posts/Config/Rprofile.site.html#初始化",
    "href": "posts/Config/Rprofile.site.html#初始化",
    "title": "Rprofile.site",
    "section": "",
    "text": "language=en\n\n\nShow the codeoptions(\"timeout\")\noptions(timeout = 180)\n\n# set a CRAN mirror\ngetOption(\"repos\")\noptions(\"BioC_mirror\")\n\n# \"https://mirrors.ustc.edu.cn/CRAN/\"\noptions(repos = c(CRAN = \"https://cran.rstudio.com/\"))\noptions(BioC_mirror = \"https://mirrors.tuna.tsinghua.edu.cn/bioconductor\")\n\n.First &lt;- function() {\n  library(showtext, quietly = T)\n  # font_add(\"Times New Roman Regular\", \"C:/Windows/Fonts/times.ttf\")\n  # font_add(\"Times New Roman Bold\", \"C:/Windows/Fonts/timesbd.ttf\")\n  # font_add(\"Times New Roman Bold Italic\", \"C:/Windows/Fonts/timesbi.ttf\")\n  # font_add(\"Times New Roman Italic\", \"C:/Windows/Fonts/timesi.ttf\")\n  # font_add(\"黑体 常规\", \"C:/Windows/Fonts/simhei.ttf\")\n  # font_add(\"楷体 常规\", \"C:/Windows/Fonts/simkai.ttf\")\n  showtext_auto()\n  # library(data.table)\n  library(conflicted)\n  library(tidyverse)\n  library(patchwork)\n  # library(BiocManager)\n  library(readxl)\n  library(writexl)\n  conflicted::conflict_scout()\n  message(today())\n}\n\n\n.Last &lt;- function() {\n\n}\n\n\n如果希望永久删除安装路径，可以直接编辑R的环境配置文件（例如 .Renviron），去掉相应的路径条目，然后重启R使更改生效。\n\nShow the code# 更新 R Gui\n\n# installr::updateR()\n\ntools &lt;- c(\n  \"installr\", \"devtools\",\"remotes\",\"conflicted\", \"reticulate\", \"BiocManager\")\n\n\nneeded &lt;- c(\n  \"tidyverse\", \"tidymodels\", \"readxl\", \"writexl\",\"plotly\",\"survminer\",\n  \"ggsurvfit\",\"arrow\"\n)\n\n# remotes::install_github(\"jbryer/psa\", build_vignettes = TRUE, dependencies = \"Enhances\")\n\noptional &lt;- c(\n  \"ggpubr\",\"pROC\", \"ggprism\", \"ggpattern\", \n  \"pheatmap\", \"ggfortify\", \"ggrepel\", \"ggthemes\",\"ggcorrplot\", \"ggpmisc\", \n  \"ggraph\", \"tidygraph\", \"svglite\",\n  \n  \n  \"gt\", \"gtsummary\", \"tableone\", \"flextable\",\n)\n\n\nlapply(tools, require)\n\n\n\n\nShow the code.libPaths()\n\n#&gt; [1] \"C:/Users/DELL/AppData/Local/R/win-library/4.4\" \"D:/R-4.4.1/library\"  \n#.libPaths(c(\"/envs/新路径\", .libPaths()))\n\n\n\nShow the code.libPaths(.libPaths()[.libPaths() != \"C:/Users/DELL/AppData/Local/R/win-library/4.4\"])\n.libPaths()"
  },
  {
    "objectID": "posts/cancer_database/UCSC/UCSC.html",
    "href": "posts/cancer_database/UCSC/UCSC.html",
    "title": "UCSC",
    "section": "",
    "text": "UCSC\nrtracklayer\n\nShow the codelibrary(rtracklayer)\nlibrary(AnnotationHub)\n\n# 第一次会下载 \nah &lt;- AnnotationHub()\n\n\n\nShow the codeah\n\n# C:/Users/DELL/AppData/Local/R/cache/R/AnnotationHub/\n\n\n\nShow the codeOrgDb_Human &lt;- subset(ah, rdataclass == \"OrgDb\" & species == \"Homo sapiens\")\nOrgDb_Human\n\norg &lt;- OrgDb_Human[[1]]\norg\n\n\n\nShow the codeGRanges_Human &lt;- subset(ah, rdataclass == \"GRanges\" & species == \"Homo sapiens\")\n\ngr &lt;- GRanges_Human[1]\ngr"
  },
  {
    "objectID": "posts/cancer_database/SEER/SEER.html",
    "href": "posts/cancer_database/SEER/SEER.html",
    "title": "SEER: The Surveillance, Epidemiology, and End Results Program",
    "section": "",
    "text": "The Surveillance, Epidemiology, and End Results (SEER)"
  },
  {
    "objectID": "posts/cancer_database/SEER/SEER.html#seerstat",
    "href": "posts/cancer_database/SEER/SEER.html#seerstat",
    "title": "SEER: The Surveillance, Epidemiology, and End Results Program",
    "section": "SEER*Stat",
    "text": "SEER*Stat\nSEER*Stat statistical software\n下载SEER*Stat\nSEER*Stat Beta"
  },
  {
    "objectID": "posts/BioProtocols/Transformation CaCl2.html",
    "href": "posts/BioProtocols/Transformation CaCl2.html",
    "title": "CaCl2 Transformation of Escherichia coli",
    "section": "",
    "text": "使用氯化钙转化大肠杆菌细胞\nTransformation of E. coli: Adapted Calcium Chloride Procedure | Microbiology | JoVe\n细菌适应性\n感受态：细菌容易吸收外源DNA的状态，摄取外部质粒DNA。 转化：细菌吸收外源DNA后引起其遗传物质的改变。\nGram-negative bacteria lipopolysaccharide (LPS)带负电 + 带负电的DNA+钙（Ca2+）这种方法主要用于革兰氏阴性菌的转化。"
  },
  {
    "objectID": "posts/BioProtocols/Transformation CaCl2.html#试剂与仪器",
    "href": "posts/BioProtocols/Transformation CaCl2.html#试剂与仪器",
    "title": "CaCl2 Transformation of Escherichia coli",
    "section": "试剂与仪器",
    "text": "试剂与仪器\n\n试剂\n\n受体大肠杆菌DH5α\n0.1mM \\(CaCl_2\\)\nLB 液体培养基(10 g casein enzymic hydrolysate, 5 g yeast extract and 5 g sodium chloride in 1000 mL of H2O) 固体培养基\n氨苄青霉素\n1X TAE buffer (40 mM Tris Base, 20 mM Acetic Acid and 1mM EDTA)\nSuper Optimal broth with Catabolite repression (SOC): (2% (w/v) tryptone, 0.5% (w/v) yeast extract, 10 mM NaCl, 2.5 mM KCl, 10 mM MgCl2, 10 mM MgSO4, and 20 mM glucose)\nPlasmid pUC19 DNA (100 pg/ µl)\n\n\n\n仪器\n分光光度计 离心机 加热机 紫外线光源"
  },
  {
    "objectID": "posts/BioProtocols/Transformation CaCl2.html#实验操作",
    "href": "posts/BioProtocols/Transformation CaCl2.html#实验操作",
    "title": "CaCl2 Transformation of Escherichia coli",
    "section": "实验操作",
    "text": "实验操作\n\n==除非另有说明，否则本方案中的所有步骤都需要使用无菌技术在冰上或4°C温度下进行==\n\n感受态细胞的制备：\n\n70%乙醇台面消毒\n从大肠杆菌DH5α的冷冻库（在LB中过夜培养的20%甘油中冷冻）中，带菌环在LB琼脂板上划线分离细菌。在37°C下培养过夜（16-20小时）\n第二天，70%乙醇台面消毒\n无菌接种环将单个菌落接种到试管中的3 mL LB肉汤中。37°C，210rpm摇床振荡生长过夜（16-20小时）。\n测量过夜培养物的OD600。将过夜培养物接种在1升烧瓶中的100 mL LB肉汤至OD600＝0.01。37°C，210 rpm摇床培养。每15-20分钟在分光光度计中监测一次OD600，直到培养物达到OD600=0.35（约3小时）~~注：为了使转化有效，细菌细胞需要处于指数生长中期。最大细胞数需要为\\(10^8\\)个细胞/mL，对于大多数大肠杆菌菌株来说，这相当于OD600=0.4。分光光度计的使用允许测量OD600，这允许确定细胞处于适当的生长阶段。如果该方案将用于其他菌株，则有必要进行校准，以确定特定OD600值下菌落形成单位的数量，从而确定这种相关性。\n将50毫升培养物转移到2个冰冷的聚丙烯大瓶中，瓶子放回冰上20分钟冷却\n4°C，2700g，离心10分钟来回收细胞。\n弃去上清液。将聚丙烯大瓶倒置在吸水纸上，沥干最后的介质痕迹。\n悬浮沉淀复合物到30mL CaCl2-MgCl2（80mM MgCl2，20mM CaCl2）冰冷溶液中。首先加入5 mL溶液，小心旋转，直到颗粒完全溶解，然后加入剩余的25 mL溶液。==禁止震荡器==\nRepeat 前两步\n如果感受态细胞要直接转化，则通过小心地旋转试管，将每个细菌颗粒重悬于2 mL CaCl2（0.1 M）冰冷溶液中。如果颗粒不能用这种方法重新悬浮，则通过上下轻轻移液进行重新悬浮（避免气泡形成）。也可以将感受态细胞冻存以备日后使用，将颗粒重悬在2毫升含有10%（v/v）甘油的0.1M CaCl2溶液中。这个解决方案需要冰冷。将等分细胞悬浮液放入冰冷的1.5 mL EP管（每管160µl）。立即在干冰/乙醇浴中冷冻感受态细胞。将试管转移到-70°C的冷冻柜中。\n\n质粒DNA转化感受态细胞\n\n将50µl感受态细胞转移到2个1.5 ml EP管中。将1µl（100 pg）的pUC19质粒DNA添加到其中一个 EP管，并使第二个 EP管不含DNA（阴性对照）。轻轻混合（避免形成气泡）。在冰上孵育30分钟.注：体积为10µL的DNA不超过50 ng\n将 EP管 在42°C下准确孵育45 s。注：热冲击是一个关键步骤。不要超过温度或培养时间。这有利于感受态细胞吸收外来DNA\n立即将 EP管 转移到冰上快速冷却2-3分钟。\n\n细胞回收：选择性培养基，回收质粒，PCR鉴定\n\n加入950µL SOC培养基，在37°C下培养管1小时，使细菌恢复并表达质粒中编码的抗生素抗性标记。\n1.5 mL EP管 在990µL SOC中稀释10µL细胞悬浮液（1/100稀释），或者，在900µL的SOC中稀释100µL细胞悬浮液（1/10稀释）。将100µl稀释液和阴性对照品涂抹到==氨苄青霉素选择性平板== 上37°C培养过夜（12-16小时）。阴性对照中不应生长菌落。注：通常，将100µL的1/100和1/10稀释液电泳，每个平板将产生足够数量的菌落形成单位（cfu）。理想情况下，这个数字应该在30-300cfu之间，这样就有足够的菌落，但彼此分离。然而，cfu的数量将取决于转化效率（见数据分析和结果部分）。\n计数转化获得的cfu/板\n\n电泳鉴定 转化细菌是否具有pUC19质粒\n\n无菌环将单个菌落接种到装有3毫升LB肉汤的试管中。37°C，210rpm摇床振荡生长过夜（16-20小时）。\n第二天，根据说明书进行质粒纯化 #plasmidDNA\n用限制性内切酶HindIII在37°C下酶解1µg纯化的pUC19 1小时。注：任何切割pUC19多克隆位点的酶都可以用于此步骤。\nDNA凝胶电泳：20μlDNA ladder，1μg酶解和1μg未酶解的质粒，95V，1h\n紫外灯\n\n\n数据分析\n\ndilution1/100 34cfu\ndilution1/10 246cfu 电泳之前\n\\[transformation\\ efficiency (TE)=\\frac{colony\\ forming\\  units (cfu)}{the \\ amount(in\\  μg)of\\  plasmid \\ DNA} / dilution(稀释)\\]\n首先将cfu除以µg 质粒DNA，在本例中为100pg=0.0001µg。然后将结果除以稀释系数。在本例中，使用1/10的稀释液，并将100µL/1 ml溶液进行电泳（稀释度：1/10×100µL/1000µL=0.01）。\n\\[TE =\\frac{246cfu}{0.0001μg} /0.01\\ dilution =2.46 ×10^8cfu/μg\\]\n对从转化细胞中回收的质粒DNA的酶解分析，对比DNA Marker，表明，该质粒具有pUC19DNA的预期大小（2686bp）。"
  },
  {
    "objectID": "posts/BioProtocols/Plasmid  DNA_purification_digestion_identification.html",
    "href": "posts/BioProtocols/Plasmid  DNA_purification_digestion_identification.html",
    "title": "Plasmid DNA purification,digestion and identification",
    "section": "",
    "text": "质粒DNA纯化、酶切与鉴定"
  },
  {
    "objectID": "posts/BioProtocols/Plasmid  DNA_purification_digestion_identification.html#试剂和仪器",
    "href": "posts/BioProtocols/Plasmid  DNA_purification_digestion_identification.html#试剂和仪器",
    "title": "Plasmid DNA purification,digestion and identification",
    "section": "试剂和仪器",
    "text": "试剂和仪器\n\n试剂\n\n纯化\n\nSolution1 GET\nSolution2 NaOH，SDS 新鲜配制\nSolution3 高盐溶液 4℃保存\nTE 缓冲液\nLB 培养基 琼脂粉Agar\n含质粒的大肠杆菌DH5α\n\n酶切与鉴定\n\nEcoR Ⅰ，BamH Ⅰ，通用缓冲液\n10× TBE缓冲液\n6×loading buffer\n菲啶溴红染色液： EB（溴化乙锭）\nGel-Red荧光染剂 核酸染料\nDNA Marker\n\n\n\n\n仪器\n恒温箱，电泳仪，离心机，紫外灯，凝胶成像仪"
  },
  {
    "objectID": "posts/BioProtocols/Plasmid  DNA_purification_digestion_identification.html#实验操作",
    "href": "posts/BioProtocols/Plasmid  DNA_purification_digestion_identification.html#实验操作",
    "title": "Plasmid DNA purification,digestion and identification",
    "section": "实验操作",
    "text": "实验操作\n\n培养细菌：将单菌落大肠杆菌接种在LB液体培养基，加入适当的抗生素，37℃培养12-18h\n纯化质粒DNA：分离细菌染色体、蛋白质、细菌胞膜、细菌核糖体\n\n收集细菌：1.5ml EP管，离心，弃去上清液\n去除RNA：GET 缓冲液，RNaseA，混匀，室温10min\n溶菌：Solution Ⅱ，颠倒混匀至清亮，冰上5min，==避免震荡==\n沉淀细菌染色体蛋白质：预冷Solution Ⅲ，颠倒混匀，冰上15min\n获取粗提质粒：离心，上清液转移入另一个干净的EP 管\n沉淀质粒：等体积异丙醇，颠倒混匀，室温5min，离心，弃去上清液\n去除杂蛋白： \\(\\ce{ ddH2O}\\)溶解沉淀，\\(\\frac{1}{2}\\)体积\\(NH_4Ac\\)，颠倒混匀冰浴5min，离心，上清液转移入另一个干净的EP 管\n沉淀质粒DNA：2倍体积无水乙醇，-20℃10min，离心，弃去上清液，吸水纸吸干\n去除EP 管中的盐：70%乙醇，颠倒，离心，弃去上清液，吸水纸吸干\n温箱干燥\n保存待用：-20℃保存或30μL TE缓冲液或\\(ddH_2O\\)溶解\n\n酶切\n\n标准酶切反应体系（20μL）：\n\n单酶切：\n\n质粒DNA X μL\n配套的10 × 缓冲液 2μL\n\\(ddH_2O\\) 20-（X+3）\n内切酶 2U（1μL）\n\n双酶切：\n\n质粒DNA X μL\n通用 10 × 缓冲液 2μL\n\\(ddH_2O\\) 20-（X+4）\n内切酶1 2U（1μL）\n内切酶2 2U（1μL）\n\n\n\n\n20μL TE缓冲液或\\(ddH_2O\\)溶解质粒DNA，==浓度？==\nEP 管编号，冰上进行，按上述依次加样，混匀\n恒温37℃，酶解2~3h\nDNA电泳或-20℃保存\n\n电泳鉴定\n\n琼脂糖凝胶\n上样：6×loading buffer 含Gel-Red ==上样量？==\n观察：254nm紫外灯 ，DNA红色荧光。305nm紫外灯，EB染色条带。"
  },
  {
    "objectID": "posts/BioProtocols/PBMCs Isolation Freezing.html",
    "href": "posts/BioProtocols/PBMCs Isolation Freezing.html",
    "title": "Peripheral Blood Mononuclear Cells: Isolation, Freezing, Thawing, and Culture",
    "section": "",
    "text": "PBMC分离、冻存、解冻和培养\nPeripheral Blood Mononuclear Cells: Isolation, Freezing, Thawing, and Culture\n外周血单个核细胞 Peripheral Blood Mononuclear Cells，包括淋巴细胞（Lymphocyte）、单核细胞（Monocyte）、树突状细胞（DC）和其他少量细胞"
  },
  {
    "objectID": "posts/BioProtocols/PBMCs Isolation Freezing.html#试剂和仪器",
    "href": "posts/BioProtocols/PBMCs Isolation Freezing.html#试剂和仪器",
    "title": "Peripheral Blood Mononuclear Cells: Isolation, Freezing, Thawing, and Culture",
    "section": "试剂和仪器",
    "text": "试剂和仪器\n\n试剂\n\n1× Phosphate Buffered Saline (PBS) Sterile PBS 无菌PBS\nFicoll Histopaque\n二甲亚砜（DMSO）\n血清白蛋白（BSA）\n10%胎牛血清（FBS）\nFreshly collected heparinised blood 新鲜采集的肝素化血液\nFicoll Histopaque (Sigma-Aldrich, catalog number: 10771; MP Biomedicals, catalog number: 091692254)：==Ficoll==是蔗糖的多聚体，中性，平均分子量400,000，当密度为1.2g/mL，未超出正常生理性渗透压，也不穿过生物膜。红细胞、粒细胞比重大，离心后沉于管底；淋巴细胞和单核细胞的比重小于或等于分层液比重，离心后漂浮于分层液的液面上，也可有少部分细胞悬浮在分层液中。吸取分层液液面的细胞，就可从外周血中分离到单个核细胞。\n细胞冻存液：FBS中加入10%DMSO\n\n\n\n仪器\n\nHeparin vials (BD Biosciences, catalog number: 367886) 肝素小瓶\nCentrifuge - Sterile 15 ml centrifuge tube 无菌15ml离心管\nPipette gun移液枪和1ml枪头"
  },
  {
    "objectID": "posts/BioProtocols/PBMCs Isolation Freezing.html#实验操作",
    "href": "posts/BioProtocols/PBMCs Isolation Freezing.html#实验操作",
    "title": "Peripheral Blood Mononuclear Cells: Isolation, Freezing, Thawing, and Culture",
    "section": "实验操作",
    "text": "实验操作\n\n收集4 ml人静脉血于肝素化小瓶中，轻轻翻转试管数次，使其充分混合\n==PBS什么时候加==等体积稀释血液\n移取4毫升Ficoll Histopaque到15ml离心管中\n使用1毫升移液枪将血液缓慢地沿管壁注入Ficoll Histopaque的顶部。血液和Ficoll Histopaque应该保持为两个不同的层。\nFixed angle rotors Centrifuge 时间min，转速×g，4℃，==？升降==\n立即（5min内）抽吸在组织水和培养基之间的界面中形成的白色棕褐色涂层（约1毫升）（PBMC）\n\n用10 ml无菌PBS洗涤（在1 x g中离心时间分钟）两次。来自4ml血液的细胞的近似产率在\\(10^7\\)~\\(10^8\\)之间变化。\n细胞计数或培养：加入5-10ml培养基重悬细胞，进行后续计数培养或者铺板；\n细胞冻存：将细胞离心收集之后，用细胞冻存液重悬。取1-1.5ml细胞至冻存管中，放入冻存盒（冻存盒可事先在4℃冰箱预冷）。再将冻存盒放置于-80℃冰箱过夜。第二天将细胞转入液氮中长期保存。\n\n\n\nFicoll Histopaque和人类血液样本、==PBS ?==之间的比例为*1:1:1。对于其它物种的PBMC的纯化比例可以是不同的。\nFicoll Histopaque储存在4°C温度下。使用前需要在室温下保持1-2小时，因为如果PBMC在预冷的Ficoll Histopaqueon血样中分层，PBMC会受到冷休克，有时会聚集"
  },
  {
    "objectID": "posts/BioProtocols/GeneKnockout.html",
    "href": "posts/BioProtocols/GeneKnockout.html",
    "title": "Gene Konckout",
    "section": "",
    "text": "基因敲除\n通过基因组编辑技术等手段，将目标基因的DNA序列从细胞或生物体中彻底删除或失活，阻断其转录和翻译过程，使目标基因完全失去功能，同时还可获得与基因敲低不同的表型。常见的基因敲除技术包括CRISPR/Cas9系统、转录激活样效应核酸酶（TALEN）技术、锌指核酸酶（Zinc finger nuclease）技术等。基因敲除技术通常能够取得更明显的表型，对于探究基因作用、疾病机制、药物靶点等方面具有更高的研究效度。\n\n基因敲除载体：\n（1）CRISPR/Cas9载体：包含Cas9核酸酶和sgRNA靶向序列，通过精确定位靶向基因DNA序列并引入双链断裂点，从而实现靶向基因的突变和敲除；\n（2）转录激活样效应核酸酶（TALENs）载体：与CRISPR/Cas9类似，包含特异性核酸酶和nuclease binding domain，通过切割靶向基因DNA序列实现敲除和编辑；\n（3）锌指核酸酶（ZFNs）载体：包含具有特异性的锌指结构域和核酸酶，通过切割靶向基因DNA序列实现敲除和编辑。\n\n\n基因敲除载体的构建方法：\n（1）设计基因敲除的靶点以及合成序列，选择CRISPR/Cas9等酶切工具对目标基因进行精确编辑，实现敲除；\n（2）将编辑过的靶点序列插入到特定的载体中；\n（3）转化编制好的敲除载体至大肠杆菌中，进行筛选鉴定，验证敲除效果；\n（4）最终通过病毒载体、电穿孔等方法将敲除载体导入到目标细胞中。"
  },
  {
    "objectID": "posts/BioProtocols/flow_cytometry.html",
    "href": "posts/BioProtocols/flow_cytometry.html",
    "title": "Flow cytometry (FC)",
    "section": "",
    "text": "流式细胞术"
  },
  {
    "objectID": "posts/BioProtocols/flow_cytometry.html#补偿compensation",
    "href": "posts/BioProtocols/flow_cytometry.html#补偿compensation",
    "title": "Flow cytometry (FC)",
    "section": "补偿Compensation",
    "text": "补偿Compensation"
  },
  {
    "objectID": "posts/BioProtocols/flow_cytometry.html#门控gating",
    "href": "posts/BioProtocols/flow_cytometry.html#门控gating",
    "title": "Flow cytometry (FC)",
    "section": "门控Gating",
    "text": "门控Gating"
  },
  {
    "objectID": "posts/BioProtocols/flow_cytometry.html#计算分析computational-analysis",
    "href": "posts/BioProtocols/flow_cytometry.html#计算分析computational-analysis",
    "title": "Flow cytometry (FC)",
    "section": "计算分析Computational analysis",
    "text": "计算分析Computational analysis\nflowClust in Bioconductor\n FlowCAP（流式细胞术：群体识别方法的关键评估）"
  },
  {
    "objectID": "posts/BioProtocols/flow_cytometry.html#荧光减一fmo-controls",
    "href": "posts/BioProtocols/flow_cytometry.html#荧光减一fmo-controls",
    "title": "Flow cytometry (FC)",
    "section": "荧光减一（FMO） controls",
    "text": "荧光减一（FMO） controls\nFluorescence minus one (FMO) \n如果您使用 4 种不同的荧光染料，您的 FMO 对照必须仅包含其中的 3 种（例如：荧光染料 – A、B、C、D;FMO – ABC_、AB_D、A_CD _BCD）"
  },
  {
    "objectID": "posts/BioProtocols/animal_models.html",
    "href": "posts/BioProtocols/animal_models.html",
    "title": "动物模型",
    "section": "",
    "text": "肿瘤动物模型"
  },
  {
    "objectID": "posts/BioProtocols/animal_models.html#原位肿瘤",
    "href": "posts/BioProtocols/animal_models.html#原位肿瘤",
    "title": "动物模型",
    "section": "原位肿瘤",
    "text": "原位肿瘤\n尾静脉高压水动力注射"
  },
  {
    "objectID": "posts/BioProtocols/animal_models.html#皮下肿瘤",
    "href": "posts/BioProtocols/animal_models.html#皮下肿瘤",
    "title": "动物模型",
    "section": "皮下肿瘤",
    "text": "皮下肿瘤\n脱毛：电推+脱毛膏\n皮下注射 100 μl"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "\\[\n     {\\color{red} { life=\\int_{birth}^{death}study \\ dt } }  \n\\]\n一些简要的笔记，方便查阅"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HomePage",
    "section": "",
    "text": "发表偏倚\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\nNov 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n重复测量方差分析\n\n\n\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n边际效应\n\n\n\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nNov 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n动物模型\n\n\n\n\n\n\nprotocols\n\n\nanimal\n\n\n\n\n\n\n\n\n\nNov 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRIS：Research Information Systems\n\n\n\n\n\n\ndatabase\n\n\n\n\n\n\n\n\n\nNov 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nsina 图\n\n\n\n\n\n\ngraphics\n\n\nggplot2 extension\n\n\n\n\n\n\n\n\n\nNov 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nconda\n\n\n\n\n\n\nconfig\n\n\n\n\n\n\n\n\n\nNov 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n亚组分析\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\nOct 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMeta 回归\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\nOct 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n森林图\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\nOct 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nScopus\n\n\n\n\n\n\ndatabase\n\n\n\n\n\n\n\n\n\nOct 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEnglish Notes\n\n\n\n\n\n\nlanguage\n\n\n\n\n\n\n\n\n\nOct 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n研究间异质性\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\nOct 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n效应大小\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\nOct 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npooling effect sizes\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\nOct 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n睿客云盘\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRprofile.site\n\n\n\n\n\n\nconfig\n\n\nR\n\n\n\n\n\n\n\n\n\nOct 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPubMed retrieval\n\n\n\n\n\n\ndatabase\n\n\n\n\n\n\n\n\n\nOct 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nreal-time Reverse Transcription PCR\n\n\n\n\n\n\nprotocols\n\n\nPCR\n\n\nDNA\n\n\nRNA\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\npolymerase chain reaction (PCR)\n\n\n\n\n\n\nprotocols\n\n\nPCR\n\n\nDNA\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nimmunoprecipitation\n\n\n\n\n\n\nprotocols\n\n\nprotein\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nenzyme-linked immunosorbent assay (ELISA)\n\n\n\n\n\n\nprotocols\n\n\nprotein\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPlasmid DNA purification,digestion and identification\n\n\n\n\n\n\nprotocols\n\n\nDNA\n\n\nplasmid\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPeripheral Blood Mononuclear Cells: Isolation, Freezing, Thawing, and Culture\n\n\n\n\n\n\nprotocols\n\n\ncell\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGene Konckout\n\n\n\n\n\n\nprotocols\n\n\nDNA\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGene Konckdown\n\n\n\n\n\n\nprotocols\n\n\nDNA\n\n\nRNAi\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nFlow cytometry (FC)\n\n\n\n\n\n\nprotocols\n\n\ncell\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCaCl2 Transformation of Escherichia coli\n\n\n\n\n\n\nprotocols\n\n\ncell\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPropensity score matching\n\n\n\n\n\n\npropensity score\n\n\n\n\n\n\n\n\n\nOct 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nZotero\n\n\n\n\n\n\nZotero\n\n\n\n\n\n\n\n\n\nOct 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nggprism: GraphPad Prism 主题风格\n\n\n\n\n\n\ngraphics\n\n\nggplot2 extension\n\n\n\n\n\n\n\n\n\nSep 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nggpattern: ggplot2 with geometric texture amd images\n\n\n\n\n\n\ngraphics\n\n\nggplot2 extension\n\n\n\n\n\n\n\n\n\nSep 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nggforce: barplot with round angle\n\n\n\n\n\n\ngraphics\n\n\nggplot2 extension\n\n\n\n\n\n\n\n\n\nSep 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nWestern Blot\n\n\n\n\n\n\nprotocols\n\n\nprotein\n\n\n\n\n\n\n\n\n\nSep 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nUCSC\n\n\n\n\n\n\nbioinformatics\n\n\ndatabase\n\n\n\n\n\n\n\n\n\nSep 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTCGA\n\n\n\n\n\n\nbioinformatics\n\n\ndatabase\n\n\n\n\n\n\n\n\n\nSep 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\niterated function system\n\n\n\n\n\n\ngraphics\n\n\nart\n\n\n\n\n\n\n\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSEER: The Surveillance, Epidemiology, and End Results Program\n\n\n\n\n\n\ndatabase\n\n\n\n\n\n\n\n\n\nSep 17, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/BioProtocols/ELISA.html",
    "href": "posts/BioProtocols/ELISA.html",
    "title": "enzyme-linked immunosorbent assay (ELISA)",
    "section": "",
    "text": "酶联免疫吸附测定\n\nSpringer Protocols\nJoVE"
  },
  {
    "objectID": "posts/BioProtocols/GeneKnockdown.html",
    "href": "posts/BioProtocols/GeneKnockdown.html",
    "title": "Gene Konckdown",
    "section": "",
    "text": "基因敲降\n是指在细胞或生物体中通过RNA干扰（RNA interference，RNAi）等方法降低目标基因表达水平，使其功能受到抑制。RNAi通常通过合成人工转录后小干扰RNA（siRNA）或利用稳定的反义RNA（shRNA）介导靶向降解mRNA来实现。由于RNAi的效果通常是部分抑制目标基因的表达，因此被称为基因敲低。基因敲低可以帮助研究者探究特定基因的生物学功能、代谢途径等，是一种常用的基因功能研究方法。\n\n基因敲降载体：\n（1）siRNA载体：短小的干扰RNA序列，通过RNAi途径靶向RNA降解或保护mRNA免受翻译；\n（2）shRNA载体：较长的干扰RNA序列，可以形成稳定的hairpin结构，通过RNAi途径实现靶向RNA降解或保护mRNA免受翻译，有效性比siRNA更高；\n（3）CRISPRi载体：包含CRISPRi靶向序列和转录抑制子，通过抑制靶向基因的转录水平实现基因敲低效果。\n\n\n基因敲降载体的构建方法：\n（1）设计目标基因的干扰序列，通常采用在线设计工具或经验公式来计算；\n（2）合成干扰序列的DNA或RNA片段，克隆到转录载体中，生成siRNA或shRNA表达载体；\n（3）将siRNA或shRNA表达载体转化至大肠杆菌中，进行筛选鉴定；\n（4）提取筛选出的重组质粒，通过腺病毒、腺相关病毒等途径将其导入到目标细胞中。"
  },
  {
    "objectID": "posts/BioProtocols/immunoprecipitation.html",
    "href": "posts/BioProtocols/immunoprecipitation.html",
    "title": "immunoprecipitation",
    "section": "",
    "text": "免疫沉淀"
  },
  {
    "objectID": "posts/BioProtocols/immunoprecipitation.html#co-immunoprecipitation-co-ip",
    "href": "posts/BioProtocols/immunoprecipitation.html#co-immunoprecipitation-co-ip",
    "title": "immunoprecipitation",
    "section": "co-immunoprecipitation (Co-IP)",
    "text": "co-immunoprecipitation (Co-IP)\n免疫共沉淀\n完整蛋白质复合物（即抗原以及与其结合的任何蛋白质或配体）的免疫沉淀称为免疫共沉淀 （Co-IP）。Co-IP 的工作原理是选择一种靶向已知蛋白质的抗体，该蛋白质被认为是更大蛋白质复合物的成员。通过用抗体靶向该已知成员，有可能将整个蛋白质复合物从溶液中拉出，从而识别复合物的未知成员。\n当复合物中涉及的蛋白质彼此紧密结合时，这种方法就会起作用，从而可以通过用抗体锁定一个成员来将复合物的多个成员从溶液中拉出。这种将蛋白质复合物从溶液中拉出的概念有时被称为“pull-down”。Co-IP 是一种强大的技术，分子生物学家经常使用它来分析蛋白质-蛋白质相互作用。"
  },
  {
    "objectID": "posts/BioProtocols/immunoprecipitation.html#chromatin-immunoprecipitation-chip",
    "href": "posts/BioProtocols/immunoprecipitation.html#chromatin-immunoprecipitation-chip",
    "title": "immunoprecipitation",
    "section": "Chromatin immunoprecipitation (ChIP)",
    "text": "Chromatin immunoprecipitation (ChIP)\n染色质免疫沉淀"
  },
  {
    "objectID": "posts/BioProtocols/PCR.html",
    "href": "posts/BioProtocols/PCR.html",
    "title": "polymerase chain reaction (PCR)",
    "section": "",
    "text": "聚合酶链式反应"
  },
  {
    "objectID": "posts/BioProtocols/PCR.html#试剂和仪器",
    "href": "posts/BioProtocols/PCR.html#试剂和仪器",
    "title": "polymerase chain reaction (PCR)",
    "section": "试剂和仪器",
    "text": "试剂和仪器\n\n试剂\n\n热稳定DNA聚合酶（taq酶，-20℃）。\n10×PCR扩增缓冲液。\n25 mmol/L \\(MgCl_2\\)。\n4种脱氧单核苷三磷酸（dNTPs）混合贮存液（20 mmol/L,pH=8.0,-20℃）\n50×TAE缓冲液\n阴性对照模板DNA\n正向引物(F,20μmol/L)及反向引物(R,20μmol/L)溶于灭菌\\(ddH_2O\\)中\nEB（溴化乙锭）或荧光染料（Gel-Red）\n\n\n\n仪器\n\nPCR管(0.2mL)\nPCR仪(Biolab,带热盖)"
  },
  {
    "objectID": "posts/BioProtocols/PCR.html#实验操作",
    "href": "posts/BioProtocols/PCR.html#实验操作",
    "title": "polymerase chain reaction (PCR)",
    "section": "实验操作",
    "text": "实验操作\n\n引物设计\n\nprimer：一小段与目的基因共享同源性的单链DNA\nfa\n\n引物配置\n\n分子量计算公式：\\[分子量 =C\\times288+A\\times312+G\\times328+T\\times303-61 \\]或者==\\[近似分子量\\approx 碱基数\\times 324.5\\]==\n引物工作浓度5-10 μmol/L,10 ×，20bp，2.0\\(OD_{260}\\) \\[1.0 OD_{260}=33\\mu g Oligo DNA\\] 终浓度为50μmol/L\n计算：\\[分子量=20\\times 324.5=6490 g/mol\\] \\[质量数=2\\times33=66\\mu g\\] \\[物质的量=66{\\div}6490=0.010μmol\\] \\[终体积=0.010{\\div}50×10^6=200μL\\]\n离心机，\\(ddH_2O\\)溶解Oligo\n\nPCR反应组分\n\n常规50μL反应体系：\n\n模板DNA1~500ng\n正向引物5~10ng\n反向引物5~10ng\n1×PCR缓冲液\n\\(MgCl_2\\)\ndNTPS混合液\nTaq酶 1unit\n\n以自制质粒DNA为模板的PCR反应：\n\n0.2mL PCR 管依次加入\n\n10×PCR扩增缓冲液（含\\(MgCl_2\\)) 5μL\n20mmol/L dNTPs混合液 1μL\n5μmol/L正向引物 2.5μL\n5μmol/L反向引物 2.5μL\n\\(ddH_2O\\) 37μL\n模板质粒DNA 1μL\n1~5U/μL Taq聚合酶 1U\n\n\n总体积 50μL\n\n\n\n设置对照组实验\n\n阳性对照：靶DNA片段\n阴性对照：P154 正向/反向引物，有/无模板DNA，非特异性配对，污染\n\nPCR仪\n\nDenaturation 高温95℃变性\nAnnealing 低温50~65℃，55℃退火\nSynthesis 中温72℃延伸\n\n产物鉴定\n\nDNA凝胶电泳\nEB染色"
  },
  {
    "objectID": "posts/BioProtocols/real-time Reverse Transcription-PCR.html",
    "href": "posts/BioProtocols/real-time Reverse Transcription-PCR.html",
    "title": "real-time Reverse Transcription PCR",
    "section": "",
    "text": "实时逆转录荧光定量PCR"
  },
  {
    "objectID": "posts/BioProtocols/real-time Reverse Transcription-PCR.html#实验操作",
    "href": "posts/BioProtocols/real-time Reverse Transcription-PCR.html#实验操作",
    "title": "real-time Reverse Transcription PCR",
    "section": "实验操作",
    "text": "实验操作\n\n目的细胞的培养\nRNA的提取 实验24\ncDNA的制备\n\n反转录体系\n引物设计\n半定量PCR反应体系\nRF PCR反应体系：SYBR Premix Ex TaqTM\n\n核糖核酸酶RNase H降解原始mRNA，留下附着在从DNA上的primer\n在DNA polymerase下合成互补链\nPCR 靶向扩增\n实时荧光定量 \n\n第一种仅在与双链DNA结合时才会在每个PCR循环结束时适当波长的光下激发染料发出荧光，非特异\n第二种使用与荧光团和猝灭剂分子相连的互补序列特异性寡核苷酸探针，持续暴露于适当波长的光下，并且猝灭剂分子在彼此靠近时吸收荧光团的荧光。DNA聚合酶在延伸过程中分离荧光团，防止淬灭\n\n分子表现出的荧光被光电探测器检测，将荧光信号转换为可读格式。==RFU==实时荧光定量RT-PCR需要配备检测器的专用PCR仪来实现实时定量\\[Threshold\\ Cycle(C_t)\\]是每个反应管内荧光信号达到设定阈值时所经历的PCR循环数，远高于背景荧光  初始样品中目标RNA的量越大，荧光显著增加的速度就越快，从而导致较低的Ct.即\\[C_t=\\frac{1}{Target RNA}\\] \\[\nCt=a×log \\  mRNA + b\n\\] 绝对定量：将样品荧光与已知 DNA 浓度制备的荧光标准曲线比较\n相对定量：将样品荧光与参考荧光比较"
  },
  {
    "objectID": "posts/BioProtocols/WB.html",
    "href": "posts/BioProtocols/WB.html",
    "title": "Western Blot",
    "section": "",
    "text": "蛋白质免疫印迹（protein immunoblot）"
  },
  {
    "objectID": "posts/BioProtocols/WB.html#试剂和仪器-云端试剂档案",
    "href": "posts/BioProtocols/WB.html#试剂和仪器-云端试剂档案",
    "title": "Western Blot",
    "section": "试剂和仪器 云端试剂档案",
    "text": "试剂和仪器 云端试剂档案\n\n试剂\n\nPBS\n高效RIPA裂解液\nWB及Co-Ip裂解液\nBCA法：A液，B液\n5 × loading buffer\n电泳缓冲液\n转膜缓冲液：700ml \\(ddH_2O\\) ： 200ml 甲醇 ：100ml 10×转膜液\n封闭液\n1×TBST\n一抗\n二抗\n一抗稀释液\n二抗稀释液\n显影液：A液，B液\n\n\n\n仪器\n\n恒温摇床\n冷冻离心机 参数 转速 半径\n96孔酶标板"
  },
  {
    "objectID": "posts/BioProtocols/WB.html#实验操作",
    "href": "posts/BioProtocols/WB.html#实验操作",
    "title": "Western Blot",
    "section": "实验操作",
    "text": "实验操作\n所有操作应于冰上/4℃ 进行\n\n蛋白提取\n\n洗涤细胞 细胞来源：动物信息、编号、性别、年龄、体重、清洁度、细胞株、基因信息\n裂解\n\n蛋白定量 样品所有人姓名，样品制备或分装年月日，全部基本信息（批号、纯度、浓度） 例如：AlexFluoro647-G3-(GfO)9,365 uM in ddH2O by UV@647nm,95%(MALDI),LY,2021.07.21\n\n96孔板\nBCA，稀释10倍\n恒温37℃孵育30min 具体：恒温孵育 9日11:34至12:05\n酶标仪，ABS，562nm 具体：在562nm的紫外吸收（A1+A2+A3/3=A平均 ） \n计算浓度\n\n蛋白变性\n\nprotein:5×loading buffer=4:1稀释\n95℃加热5分钟\n若是Co-IP，利用beads说明书\n\n计算上样量\n\n\\(\\frac{上样量(μg)}{c×8}\\)\n\n电泳\n\n预制胶，撕掉红色条膜\n电泳液\n恒压100-140V，60min\n\n转膜\n\n甲醇激活膜\n凝胶水冲，转膜液激活，“黑胶”\n转膜液平衡膜\n“白膜”\n赶走气泡\n恒流280mA，60-90min\n\n封闭\n\n5%奶粉TBST溶液\n摇床50，1h\n\n一抗孵育\n\n一抗稀释液1：1000\n摇床50，4℃ .pm~ .am,\nTBST洗涤，3min×3\n\n二抗孵育\n\n二抗稀释液1：4000~5000\n摇床50，室温1h\nTBST洗涤，3min×3\n\n显影\n\n配制显影液\n显影仪 电脑文件夹数据图像命名：姓名日期参数Marker/Samples 结果：具体数值/图像/现象/颜色\n\n\n多用图表\n\nWB\n\n\n步骤\n2024-11-12\n2024-11-14\n……\n2024-11-19\n\n\n\n\n1.动物模型\n\n\n\n\n\n\n2.细胞\n\n\n\n\n\n\n3.蛋白提取\n\n\n\n\n\n\n4.蛋白定量\n\n\n\n\n\n\n……\n\n\n\n\n\n\n\n成功的失败的、反思总结\n重复、阴性对照\n奇偶页法\n左边写实验设计 假设 对照 原始数据 草图 现象\n右边正式步骤 数据 分析\n所有过程都务必记录"
  },
  {
    "objectID": "posts/cancer_database/TCGA/TCGA.html",
    "href": "posts/cancer_database/TCGA/TCGA.html",
    "title": "TCGA",
    "section": "",
    "text": "https://portal.gdc.cancer.gov/\nhttps://www.jingege.wang/2024/02/25/tcga-gdc-data-portal-2-0/\nhttps://www.jingege.wang/2022/07/16/tcgar/\n\nShow the codelibrary(jsonlite)\n\njson &lt;- jsonlite::fromJSON(\"data/metadata.cart.2024-07-04.json\") |&gt; as_tibble()\n\njson |&gt; select(associated_entities)\n\n# A tibble: 536 × 1\n   associated_entities\n   &lt;list&gt;             \n 1 &lt;df [1 × 4]&gt;       \n 2 &lt;df [1 × 4]&gt;       \n 3 &lt;df [1 × 4]&gt;       \n 4 &lt;df [1 × 4]&gt;       \n 5 &lt;df [1 × 4]&gt;       \n 6 &lt;df [1 × 4]&gt;       \n 7 &lt;df [1 × 4]&gt;       \n 8 &lt;df [1 × 4]&gt;       \n 9 &lt;df [1 × 4]&gt;       \n10 &lt;df [1 × 4]&gt;       \n# ℹ 526 more rows\n\nShow the codejson$associated_entities[[1]]\n\n           entity_submitter_id entity_type                              case_id\n1 TCGA-38-7271-01A-11R-2039-07     aliquot 8214a0d1-5e2d-4a7a-acb1-e5580755db83\n                             entity_id\n1 8d895d3d-9598-459b-813e-3fc84dd3efe8\n\nShow the code# sample_id &lt;- map_vec(json$associated_entities,~ .x[,1])\nsample_id &lt;- sapply(json$associated_entities,function(x){x[,1]})\n\n\nfile_sample &lt;- tibble(sample_id,file_name=json$file_name) \n\n\n\nShow the code#获取gdc_download文件夹下的所有TSV表达文件的 路径+文件名\ncount_file &lt;- list.files(\"data/gdc_download_20240704_131631.625023\",pattern = \"*.tsv\",recursive = TRUE)\n#在count_file中分割出文件名\ncount_file_name &lt;- str_split(count_file,pattern = '/') \n\ncount_file_name &lt;- sapply(count_file_name,function(x){x[2]})\n\n\n\n\nShow the codematrix = data.frame(matrix(nrow=60660,ncol=0))\n\n\nfor (i in 1:length(count_file)) {\n    path = paste0('data/gdc_download_20240704_131631.625023/',\n                  count_file[i])\n    data &lt;- read_tsv(path, col_names = T, skip = 1)\n    data &lt;- data[-c(1:4), c(1, 4)] |&gt; column_to_rownames(var = \"gene_id\")  #取出ESEMBL_id列1 和 unstranded列 4，即count数据，对应其它数据，第2列为gene symbol\n    colnames(data) &lt;- file_sample$sample_id[which(file_sample$file_name == count_file_name[i])]\n    \n    matrix &lt;- cbind(matrix, data)\n}\nwrite.csv(matrix,'data/COUNT_matrix.csv',row.names = TRUE)\n\n\n\n根据TCGA样本的命名可以区分正常组织和肿瘤样本的测序结果 其中 14、15位置编号大于10 表示正常\n\nShow the codeCOUNT_matrix &lt;- read_csv('data/COUNT_matrix.csv') |&gt; column_to_rownames(var = \"...1\")\n\n\nstr_sub(colnames(COUNT_matrix),14,15) |&gt; table()\n\n\n 01  02  11 \n481   2  53 \n\n\n\n\nShow the codejson &lt;- jsonlite::fromJSON(\"data/metadata.cart.2024-07-04.json\")\n\nentity_submitter_id &lt;- sapply(json$associated_entities,function(x){x[,1]})\ncase_id &lt;- sapply(json$associated_entities,function(x){x[,3]})\nsample_case &lt;- t(rbind(entity_submitter_id,case_id)) |&gt; as_tibble()\n\nclinical &lt;- read.delim('data/clinical.cart.2024-07-04/clinical.tsv',header = T)\n\nclinical &lt;- clinical |&gt; distinct(case_id,.keep_all = TRUE)\n\n\n\n\n\nclinical_matrix &lt;- left_join(sample_case,clinical,by = join_by(case_id))\n\nclinical_matrix &lt;- clinical_matrix |&gt; select(-case_id)\n\n\n\nhttps://bioconductor.org/packages/release/workflows/html/TCGAWorkflow.html"
  },
  {
    "objectID": "posts/cancer_database/TCGA/TCGA.html#计数矩阵",
    "href": "posts/cancer_database/TCGA/TCGA.html#计数矩阵",
    "title": "TCGA",
    "section": "",
    "text": "Show the codematrix = data.frame(matrix(nrow=60660,ncol=0))\n\n\nfor (i in 1:length(count_file)) {\n    path = paste0('data/gdc_download_20240704_131631.625023/',\n                  count_file[i])\n    data &lt;- read_tsv(path, col_names = T, skip = 1)\n    data &lt;- data[-c(1:4), c(1, 4)] |&gt; column_to_rownames(var = \"gene_id\")  #取出ESEMBL_id列1 和 unstranded列 4，即count数据，对应其它数据，第2列为gene symbol\n    colnames(data) &lt;- file_sample$sample_id[which(file_sample$file_name == count_file_name[i])]\n    \n    matrix &lt;- cbind(matrix, data)\n}\nwrite.csv(matrix,'data/COUNT_matrix.csv',row.names = TRUE)"
  },
  {
    "objectID": "posts/cancer_database/TCGA/TCGA.html#normal-和-tumor",
    "href": "posts/cancer_database/TCGA/TCGA.html#normal-和-tumor",
    "title": "TCGA",
    "section": "",
    "text": "根据TCGA样本的命名可以区分正常组织和肿瘤样本的测序结果 其中 14、15位置编号大于10 表示正常\n\nShow the codeCOUNT_matrix &lt;- read_csv('data/COUNT_matrix.csv') |&gt; column_to_rownames(var = \"...1\")\n\n\nstr_sub(colnames(COUNT_matrix),14,15) |&gt; table()\n\n\n 01  02  11 \n481   2  53"
  },
  {
    "objectID": "posts/cancer_database/TCGA/TCGA.html#表型矩阵",
    "href": "posts/cancer_database/TCGA/TCGA.html#表型矩阵",
    "title": "TCGA",
    "section": "",
    "text": "Show the codejson &lt;- jsonlite::fromJSON(\"data/metadata.cart.2024-07-04.json\")\n\nentity_submitter_id &lt;- sapply(json$associated_entities,function(x){x[,1]})\ncase_id &lt;- sapply(json$associated_entities,function(x){x[,3]})\nsample_case &lt;- t(rbind(entity_submitter_id,case_id)) |&gt; as_tibble()\n\nclinical &lt;- read.delim('data/clinical.cart.2024-07-04/clinical.tsv',header = T)\n\nclinical &lt;- clinical |&gt; distinct(case_id,.keep_all = TRUE)\n\n\n\n\n\nclinical_matrix &lt;- left_join(sample_case,clinical,by = join_by(case_id))\n\nclinical_matrix &lt;- clinical_matrix |&gt; select(-case_id)"
  },
  {
    "objectID": "posts/cancer_database/TCGA/TCGA.html#tcgaworkflow",
    "href": "posts/cancer_database/TCGA/TCGA.html#tcgaworkflow",
    "title": "TCGA",
    "section": "",
    "text": "https://bioconductor.org/packages/release/workflows/html/TCGAWorkflow.html"
  },
  {
    "objectID": "posts/Config/conda.html",
    "href": "posts/Config/conda.html",
    "title": "conda",
    "section": "",
    "text": "https://conda.io/projects/conda/en/latest/user-guide/getting-started.html https://docs.anaconda.com\nminiconda内置包不全，没有anaconda方便"
  },
  {
    "objectID": "posts/Config/conda.html#conda环境管理",
    "href": "posts/Config/conda.html#conda环境管理",
    "title": "conda",
    "section": "conda环境管理",
    "text": "conda环境管理\n\nShow the codelibrary(reticulate)\n# 查看当前可用conda环境\nconda_list()\npy_config(\n\n\n\nShow the codeuse_condaenv(condaenv = \"base\", required = TRUE)\n\n\nconda_create(envname = \"r-reticulate\") \nconda_install(envname = \"base\", packages = c(\"polars\"))\n\n\n\nShow the codeconda_remove(envname = \"r-reticulate\")\nconda_clone()\nconda_export()\nconda_update()\nconda_version() # conda版本信息"
  },
  {
    "objectID": "posts/Config/conda.html#condapip安装",
    "href": "posts/Config/conda.html#condapip安装",
    "title": "conda",
    "section": "conda/pip安装",
    "text": "conda/pip安装\n\nShow the codepy_module_available(\"pip\")\npy_module_available(\"numpy\")\npy_module_available(\"polars\")\n\n\n\n\npip &lt;command&gt; [options]\n\n\n\n\npip install &lt;module&gt;\npip install SpeechRecognition -i https://pypi.tuna.tsinghua.edu.cn/simple/\n\n\n\npip uninstall &lt;module&gt;\n\n\npip list\n\n\npip –version pip -V\n\n\npython -m pip install –upgrade pip"
  },
  {
    "objectID": "posts/Config/conda.html#调用python",
    "href": "posts/Config/conda.html#调用python",
    "title": "conda",
    "section": "调用Python",
    "text": "调用Python\n\nShow the code# python脚本\npy_run_file(\"helloworld.py\")\n\nsource_python(\"helloworld.py\")\n\n\n\nShow the code# Python 交互\nreticulate::repl_python()\n\n\n\nShow the codepl &lt;- import(\"polars\")\n\npl$read_clipboard()"
  },
  {
    "objectID": "posts/Graphics/Art/iterated function system.html",
    "href": "posts/Graphics/Art/iterated function system.html",
    "title": "iterated function system",
    "section": "",
    "text": "Art code\n\nShow the codelibrary(Rcpp)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(ggthemes)\nlibrary(tictoc)\n\n\n\nShow the codefern_transform &lt;- function(coord, ind) {\n  \n  # coefficients for the stem function f_1\n  if(ind == 1) {\n    mat &lt;- matrix(c(0, 0, 0, .16), 2, 2) # matrix to multiply\n    off &lt;- c(0, 0)                       # offset vector to add\n  }\n  \n  # coefficients for the small leaflet function f_2\n  if(ind == 2) {\n    mat &lt;- matrix(c(.85, -.04, .04, .85), 2, 2)\n    off &lt;- c(0, 1.6)                      \n  }\n  # coefficients for the right-side function f_3\n  if(ind == 3) {\n    mat &lt;- matrix(c(.2, .23, -.26, .22), 2, 2)\n    off &lt;- c(0, 1.6)                      \n  }\n  \n  # coefficients for the left-side function f_4\n  if(ind == 4) {\n    mat &lt;- matrix(c(-.15, .26, .28, .24), 2, 2)\n    off &lt;- c(0, .44)                     \n  }\n  \n  # return the affine transformed coords\n  coord &lt;- mat %*% coord + off\n  return(coord)\n}\n\n\n\nShow the codefern_chaos &lt;- function(iterations = 10000, seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  \n  # which transformation to apply at each iteration\n  transform_index &lt;- sample(\n    x = 1:4, \n    size = iterations, \n    replace= TRUE, \n    prob = c(.01, .85, .07, .07)\n  )\n  \n  # initialise chaos game at the origin\n  start &lt;- matrix(c(0, 0))\n  \n  # helper function to collapse accumulated output\n  bind_to_column_matrix &lt;- function(lst) {\n    do.call(cbind, lst)\n  }\n  \n  # iterate until done!\n  coord_matrix &lt;- transform_index |&gt;\n    accumulate(fern_transform, .init = start) |&gt;\n    bind_to_column_matrix() \n  \n  # tidy the output, add extra columns, and return\n  coord_df &lt;- t(coord_matrix) |&gt; \n    as.data.frame() \n  names(coord_df) &lt;- c(\"x\", \"y\")\n  coord_df &lt;- coord_df |&gt;\n    as_tibble() |&gt;\n    mutate(\n      transform = c(0, transform_index),\n      iteration = row_number() - 1\n    )\n  return(coord_df)\n}\n\n\n\nShow the codefern_dat &lt;- fern_chaos(seed = 1)\nfern_dat %&gt;% head()\n\n# A tibble: 6 × 4\n       x     y transform iteration\n   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1  0      0            0         0\n2  0      1.6          2         1\n3  0.064  2.96         2         2\n4  0.173  4.11         2         3\n5 -1.03   2.54         3         4\n6 -0.778  3.80         2         5\n\n\n\nShow the codeggplot(fern_dat, aes(x, y)) +\n  geom_point(colour = \"yellow\", size = 1, stroke = 0) +\n  coord_equal() +\n  theme_void()\n\n\n\n\n\n\n\n\nShow the codeggplot(fern_dat, aes(x, y, colour = iteration)) +\n  geom_point(size = 1, stroke = 0, show.legend = FALSE) +\n  coord_equal() +\n  theme_void()"
  },
  {
    "objectID": "posts/Graphics/ggforce/sina.html",
    "href": "posts/Graphics/ggforce/sina.html",
    "title": "sina 图",
    "section": "",
    "text": "（小提琴图 + 抖散图）= sina 图\n\nShow the codeif(!require(ggforce)) install.packages(\"ggforce\")\n\n\n\nShow the codelibrary(ggforce)\n\n\nggplot(mpg,aes(x = drv, y = hwy ))+\n     geom_violin()+\n    geom_sina(size = 0.85)\n\n\n\n\n\n\n\n\nShow the codeggplot(mpg,aes(x = drv, y = hwy ))+\n    geom_violin()+\n    geom_jitter(width = 0.25, size = 0.85)"
  },
  {
    "objectID": "posts/Graphics/ggprism/ggprism.html",
    "href": "posts/Graphics/ggprism/ggprism.html",
    "title": "ggprism: GraphPad Prism 主题风格",
    "section": "",
    "text": "GraphPad Prism 主题风格"
  },
  {
    "objectID": "posts/Graphics/ggprism/ggprism.html#先决条件",
    "href": "posts/Graphics/ggprism/ggprism.html#先决条件",
    "title": "ggprism: GraphPad Prism 主题风格",
    "section": "先决条件",
    "text": "先决条件\n\nShow the codeif(!require(ggprism)) install.packages(\"ggprism\")\n\n\n\nShow the codelibrary(patchwork)\nToothGrowth$dose &lt;- as.factor(ToothGrowth$dose)\n\n\n\nShow the codenames(ggprism_data$themes)\n\n [1] \"autumn_leaves\"   \"beer_and_ales\"   \"black_and_white\" \"candy_bright\"   \n [5] \"candy_soft\"      \"colorblind_safe\" \"colors\"          \"diazo\"          \n [9] \"earth_tones\"     \"evergreen\"       \"greenwash\"       \"muted_rainbow\"  \n[13] \"office\"          \"purple_passion\"  \"shades_of_gray\"  \"summer\"         \n[17] \"the_blues\"       \"winter_soft\"     \"stained_glass\"   \"warm_pastels\"   \n[21] \"flames\"          \"floral\"          \"inferno\"         \"magma\"          \n[25] \"mustard_field\"   \"neon\"            \"pastels\"         \"pearl\"          \n[29] \"plasma\"          \"prism_dark\"      \"prism_light\"     \"quiet\"          \n[33] \"spring\"          \"starry\"          \"viridis\"         \"waves\"          \n[37] \"blueprint\"       \"fir\"             \"ocean\"           \"sunny_garden\"   \n[41] \"wool_muffler\"    \"warm_and_sunny\"  \"winter_bright\"   \"all_null\"       \n\nShow the codepreview_theme(\"colors\")\n\n\n\n\n\n\n\n\nShow the codelengths(ggprism_data$colour_palettes)\n\n  autumn_leaves   beer_and_ales black_and_white       blueprint      blueprint2 \n              9               9               9               9               9 \n     blueprint3    candy_bright      candy_soft colorblind_safe          colors \n              9               9               9               6              20 \n          diazo     earth_tones       evergreen             fir            fir2 \n              9              10               9               9               9 \n           fir3          flames         flames2          floral         floral2 \n              9               9               9              12              12 \n      greenwash         inferno           magma   mustard_field  mustard_field2 \n             10               6               6               9               9 \n  muted_rainbow            neon           ocean          ocean2          ocean3 \n             10               9               9               9               9 \n         office         pastels           pearl          pearl2          plasma \n              9               9               6               6               6 \n     prism_dark     prism_dark2     prism_light    prism_light2  purple_passion \n             10              10              10              10               9 \n          quiet          quiet2  shades_of_gray          spring         spring2 \n              9               9               9               9               9 \n  stained_glass  stained_glass2          starry         starry2          summer \n              9               9               5               5              10 \n   sunny_garden   sunny_garden2   sunny_garden3       the_blues         viridis \n              9               9               9               9               6 \n warm_and_sunny    warm_pastels   warm_pastels2           waves          waves2 \n              9               9               9               5               5 \n  winter_bright     winter_soft    wool_muffler   wool_muffler2   wool_muffler3 \n              9               9               9               9               9"
  },
  {
    "objectID": "posts/Graphics/ggprism/ggprism.html#ggprism",
    "href": "posts/Graphics/ggprism/ggprism.html#ggprism",
    "title": "ggprism: GraphPad Prism 主题风格",
    "section": "ggprism",
    "text": "ggprism\n散点图\n\nShow the codep1 &lt;- ggplot(msleep[complete.cases(msleep), ], \n             aes(x = sleep_rem, y = sleep_total)) + \n  geom_point(aes(shape = factor(vore)), size = 3) + \n  theme_prism() + \n  theme(axis.title.y = element_blank())\n\np2 &lt;- p1 + scale_shape_prism()\n\np1 + p2\n\n\n\n\n\n\n\n柱状图\n\nShow the codep1 &lt;- ggplot(ToothGrowth, aes(x = dose, y = len)) + \n  stat_summary(aes(fill = dose),\n               geom = \"col\", fun = mean, colour = \"black\", linewidth = 0.9) + \n  scale_y_continuous(limits = c(0, 30), expand = c(0, 0))\n\np2 &lt;- p1 + theme_prism(base_size = 14)\n\np1 + p2\n\n\n\n\n\n\n\n箱线图\n\nShow the codep &lt;- ggplot(ToothGrowth, aes(x = supp, y = len)) + \n  geom_boxplot(aes(colour = supp, fill = supp)) + \n  theme_prism(base_size = 12)\n\np1 &lt;- p + scale_colour_prism(palette = \"floral\") + \n  scale_fill_prism(palette = \"floral\")\n\np2 &lt;- p + scale_colour_prism(palette = \"flames\") + \n  scale_fill_prism(palette = \"flames\")\n\np1 + p2\n\n\n\n\n\n\n\n小提琴图\n\nShow the codep_vals &lt;- tibble::tribble(\n  ~group1, ~group2, ~p.adj,   ~y.position,\n  \"0.5\",   \"1\",     8.80e-14, 35,\n  \"0.5\",   \"2\",     1.27e-7,  39\n)\n\n\np1 &lt;- ggplot(ToothGrowth, aes(x = dose, y = len)) + \n  geom_violin(aes(colour = dose, fill = dose), trim = FALSE) + \n  geom_boxplot(aes(fill = dose), width = 0.2, colour = \"black\") + \n  scale_y_continuous(limits = c(-5, 40))+\n    add_pvalue(p_vals, label = \"p = {p.adj}\", tip.length = 0, label.size = 4)\n\n\np2 &lt;- p1 + \n  scale_color_prism(\"floral\") + \n  scale_fill_prism(\"floral\") + \n  theme_prism(base_size = 12) + \n  theme(legend.position = \"none\") + \n  add_pvalue(p_vals, label = \"p = {p.adj}\", tip.length = 0, label.size = 4)\n\n\np1+p2\n\n\n\n\n\n\n\n轴\n\nShow the codep &lt;- ggplot(ToothGrowth, aes(x = dose, y = len)) + \n  geom_jitter(aes(shape = dose), width = 0.2, size = 2) + \n  scale_shape_prism() + \n  theme_prism() + \n  theme(legend.position = \"none\")\n\np1 &lt;- p + scale_y_continuous(limits = c(0, 40), guide = \"prism_minor\")\n\np2 &lt;- p + scale_x_discrete(guide = \"prism_bracket\") + \n  scale_y_continuous(limits = c(0, 40))\n\np3 &lt;- p + scale_y_continuous(limits = c(0, 40), guide = \"prism_offset\")\n\np4 &lt;- p + scale_y_continuous(limits = c(0, 40), guide = \"prism_offset_minor\")\n\n(p1 + p2) / (p3 + p4)\n\n\n\n\n\n\n\n不连续轴\n\nShow the code# multiply one of the len values by 100\ntg &lt;- ToothGrowth\ntg[2, \"len\"] &lt;- tg[2, \"len\"] * 100\n\n\nggplot(tg, aes(x = dose, y = len)) + \n  geom_jitter(aes(shape = dose), width = 0.2, size = 2) + \n  scale_shape_prism() + \n  theme_prism() + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nShow the codep_bottom &lt;- ggplot(tg, aes(x = dose, y = len)) + \n  geom_jitter(aes(shape = dose), width = 0.2, size = 2) + \n  scale_shape_prism() + \n  coord_cartesian(ylim = c(0, 60)) + \n  guides(x = \"prism_bracket\", y = \"prism_offset_minor\") + \n  theme_prism() + \n  theme(legend.position = \"none\")\n\np_bottom\n\n\n\n\n\n\n\n\nShow the codep_top &lt;- ggplot(tg, aes(x = dose, y = len)) + \n  geom_jitter(aes(shape = dose), width = 0.2, size = 2) + \n  scale_shape_prism() + \n  coord_cartesian(ylim = c(1140, 1160)) +\n  scale_y_continuous(breaks = c(1140, 1160)) +\n  guides(y = \"prism_offset_minor\")\n\ntheme_outlier &lt;- function(palette = \"black_and_white\",\n                          base_size = 14,\n                          base_family = \"sans\",\n                          base_fontface = \"bold\",\n                          base_line_size = base_size/14,\n                          base_rect_size = base_size/14,\n                          axis_text_angle = 0,\n                          border = FALSE) {\n  theme_prism(palette = palette,\n              base_size = base_size,\n              base_family = base_family,\n              base_fontface = base_fontface,\n              base_line_size = base_line_size,\n              base_rect_size = base_rect_size,\n              axis_text_angle = axis_text_angle,\n              border = border) %+replace% \n    theme(axis.title = element_blank(),\n          axis.text.x = element_blank(),\n          axis.ticks.x = element_blank(),\n          axis.line.x = element_blank(),\n          legend.position = \"none\")\n}\n\np_top &lt;- p_top + theme_outlier()\np_top\n\n\n\n\n\n\nShow the codep_top / p_bottom + \n  plot_layout(heights = c(1, 4)) & \n  theme(axis.text.y = element_text(colour = \"red\"))\n\n\n\n\n\n\n\np值\n\nShow the code# create a jitter plot of the sleep data set\n# and indicate the means\np &lt;- ggplot(sleep, aes(x = group, y = extra)) +\n  geom_jitter(aes(shape = group), width = 0.1) + \n  stat_summary(geom = \"crossbar\", fun = mean, colour = \"red\", width = 0.2) + \n  theme_prism() + \n  theme(legend.position = \"none\")\np\n\n\n\n\n\n\n\n\nShow the coderesult &lt;- t.test(extra ~ group, data = sleep)$p.value\nresult &lt;- signif(result, digits = 3)\nresult\n\n[1] 0.0794\n\nShow the codedf_p_val &lt;- data.frame(\n  group1 = \"1\",\n  group2 = \"2\",\n  label = result,\n  y.position = 6\n)\n\n\n\nShow the codecolnames(df_p_val) &lt;- c(\"apple\", \"banana\", \"some_label\", \"some_y_position\")\n\n# add p-value brackets again\np + add_pvalue(df_p_val,\n                     xmin = \"apple\",\n                     xmax = \"banana\",\n                     label = \"some_label\",\n                     y.position = \"some_y_position\")\n\n\n\n\n\n\n\n\nShow the codecolnames(df_p_val) &lt;- c(\"group1\", \"group2\", \"label\", \"y.position\")\n# change bracket and label aesthetics\np1 &lt;- p + add_pvalue(df_p_val,\n                     colour = \"red\", # label\n                     label.size = 8, # label\n                     fontface = \"bold\", # label\n                     fontfamily = \"serif\", # label\n                     angle = 45, # label\n                     hjust = 1, # label\n                     vjust = 2, # label\n                     bracket.colour = \"blue\", # bracket\n                     bracket.size = 1, # bracket\n                     linetype = \"dashed\", # bracket\n                     lineend = \"round\") # bracket\n\n# use glue expression for label\np2 &lt;- p + add_pvalue(df_p_val, label = \"p = {label}\")\n\n# make bracket tips longer and use coord_flip\np3 &lt;- p + add_pvalue(df_p_val, tip.length = 0.15, coord.flip = TRUE) + \n  coord_flip()\n\n# change bracket tips independently\n# (make one side disappear and the other longer)\np4 &lt;- p + add_pvalue(df_p_val, tip.length = c(0.2, 0))\n\n(p1 + p2) / (p3 + p4)\n\n\n\n\n\n\n\n+ rstatix\n\n\nShow the codep &lt;- ggplot(ToothGrowth, aes(x = dose, y = len)) +\n  geom_boxplot(aes(fill = dose), colour = \"black\") + \n  theme_prism() + \n  theme(legend.position = \"none\")\n\ndf_p_val &lt;- rstatix::t_test(ToothGrowth, len ~ dose, ref.group = \"0.5\") %&gt;% \n  rstatix::add_xy_position()\n\np + add_pvalue(df_p_val, \n               label = \"p = {p.adj}\",\n               remove.bracket = TRUE)"
  },
  {
    "objectID": "posts/literature_retrieval/export_format.html",
    "href": "posts/literature_retrieval/export_format.html",
    "title": "RIS：Research Information Systems",
    "section": "",
    "text": "Reference Manager\nRIS 文件格式是一种用于表示书目引文的标记格式,以两个字母、两个空格和一个连字符， 各行必须以 ASCII 回车符和换行符结尾（ Microsoft Windows）。\n记录以”end record” ER  -结束，记录之间没有额外的空行\nRIS 维基百科\nClaude E. Shannon. A mathematical theory of communication. Bell System Technical Journal, 27:379–423, July 1948\nRIS Tags\nTY  - JOUR\nAU  - Shannon, Claude E.\nPY  - 1948\nDA  - July\nTI  - A Mathematical Theory of Communication\nT2  - Bell System Technical Journal\nSP  - 379\nEP  - 423\nVL  - 27\nER  - \nTY  - JOUR\nT1  - On computable numbers, with an application to the Entscheidungsproblem\nA1  - Turing, Alan Mathison\nJO  - Proc. of London Mathematical Society\nVL  - 47\nIS  - 1\nSP  - 230\nEP  - 265\nY1  - 1937\nER  -"
  },
  {
    "objectID": "posts/literature_retrieval/Scopus.html",
    "href": "posts/literature_retrieval/Scopus.html",
    "title": "Scopus",
    "section": "",
    "text": "图书馆首页 =&gt; 讲座培训 =&gt; 信息检索培训"
  },
  {
    "objectID": "posts/literature_retrieval/Scopus.html#检索技巧",
    "href": "posts/literature_retrieval/Scopus.html#检索技巧",
    "title": "Scopus",
    "section": "检索技巧",
    "text": "检索技巧"
  },
  {
    "objectID": "posts/literature_retrieval/Scopus.html#多角度研究成果分析",
    "href": "posts/literature_retrieval/Scopus.html#多角度研究成果分析",
    "title": "Scopus",
    "section": "多角度研究成果分析",
    "text": "多角度研究成果分析\n作者档案\n自动追踪作者：主页设置通知"
  },
  {
    "objectID": "posts/literature_retrieval/Scopus.html#期刊评价",
    "href": "posts/literature_retrieval/Scopus.html#期刊评价",
    "title": "Scopus",
    "section": "期刊评价",
    "text": "期刊评价\nJCR 影响因子\n领域加权的引用影响（FWCI ）\nH-index\nCiteScore：期刊4年内"
  },
  {
    "objectID": "posts/MetaAnalysis/effect_sizes.html",
    "href": "posts/MetaAnalysis/effect_sizes.html",
    "title": "效应大小",
    "section": "",
    "text": "Doing Meta-Analysis in R: A Hands-on Guide\n效应大小（effect sizes）+标准误"
  },
  {
    "objectID": "posts/MetaAnalysis/effect_sizes.html#观察性研究",
    "href": "posts/MetaAnalysis/effect_sizes.html#观察性研究",
    "title": "效应大小",
    "section": "观察性研究",
    "text": "观察性研究\n算术均值\n\\[\n\\bar x =\\frac{\\sum_{i=1}^n x_i}{n}\n\\]\n\\[\nSE_{\\bar x} = \\frac{s}{\\sqrt{n}}\n\\]\n\nShow the codeset.seed(123)\nsample &lt;- rnorm(n = 50, mean = 20, sd = 5)\nmean(sample)\n\n[1] 20.17202\n\nShow the codesd(sample)/sqrt(50)\n\n[1] 0.6546889\n\n\n要对均值进行荟萃分析，我们的数据集至少应包含以下列：\n\nn 研究中观测值的数量 （样本量）。\nmean 研究中报告的平均值。\nsd 研究中报告的变量的标准差。\n比例\n\\[\np=\\frac{k}{n}\n\\]\n\\[\nSE_{p} = \\sqrt{\\frac{p(1-p)}{n}}\n\\]\n\nShow the codek &lt;- 25\nn &lt;- 125\n\np &lt;- k/n\np\n\n[1] 0.2\n\nShow the codesqrt((p*(1-p))/n)\n\n[1] 0.03577709\n\n\nlogit 转换确保采样分布大致正态\n\\[\np_{\\text{logit}} = \\log_{e} \\left(\\frac{p}{1-p}\\right)\n\\]\n\\[\nSE_{p_{\\text{logit}}} = \\sqrt{\\frac{1}{np}+\\frac{1}{n(1-p)}}\n\\]\nR 中使用的元分析函数会自动执行这种 logit 转换\n我们的数据集至少应包含以下列：\n\nn 研究中的总样本量。\nk 研究中指定亚组的样本量。\n相关性\nPearson Product-Moment Correlation\n两个连续变量\n\\[\nr_{xy} = \\frac{\\sigma^{2}_{xy}}{\\sigma_x \\sigma_y}\n\\]\n\\[\nSE_{r_{xy}} = \\frac{1-r_{xy}^2}{\\sqrt{n-2}}\n\\]\n\nr≈0.10：效果小。\nr≈0.30：中等效果。\nr≈0.50：大效果。\n\n在元分析中，相关性通常转化为 Fisher’s z\n\\[\nz = 0.5\\log_{e}\\left(\\frac{1+r}{1-r}\\right)\n\\]\n\\[\nSE_{z} = \\frac{1}{\\sqrt{n-3}}\n\\]\n\nShow the codeset.seed(12345)\nx &lt;- rnorm(20, 50, 10)\ny &lt;- rnorm(20, 10, 3)\n\nr &lt;- cor(x,y)\nr\n\n[1] 0.2840509\n\n\n\nShow the codez &lt;- 0.5*log((1+r)/(1-r))\nz\n\n[1] 0.2920831\n\n\n在 R 中对相关性进行荟萃分析时手动转换。我们在数据集中唯一需要的列是：\n\nCOR 研究的（未转换的）相关系数。\nn. 研究的样本量。\nPoint-Biserial Correlation\ny是连续变量，x是二分类变量\n\\[\n{r_{pb}}= \\frac{(\\bar{y_1}-\\bar{y_2})\\sqrt{p_1(1-p_1)}}{s_y}\n\\]"
  },
  {
    "objectID": "posts/MetaAnalysis/effect_sizes.html#实验性研究",
    "href": "posts/MetaAnalysis/effect_sizes.html#实验性研究",
    "title": "效应大小",
    "section": "实验性研究",
    "text": "实验性研究\n(Standardized) Mean Differences\n组间均值差值\n\\[\n\\text{MD}_{\\text{between}} = \\bar{x}_1 - \\bar{x}_2\n\\]\n\\[\nSE_{\\text{MD}_{\\text{between}}} = s_{\\text{pooled}}\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2}}\n\\]\n其中，\\(s_{pooled}\\) 表示两组的合并标准差\n\\[\ns_{\\text{pooled}} = \\sqrt{\\frac{(n_1-1)s^2_1+(n_2-1)s^2_2}{(n_1-1)+(n_2-1)}}\n\\]\n\nShow the codeset.seed(123)\nx1 &lt;- rnorm(n = 20, mean = 10, sd = 3)\nx2 &lt;- rnorm(n = 20, mean = 15, sd = 3)\n\ns1 &lt;- sd(x1)\ns2 &lt;- sd(x2)\nn1 &lt;- 20\nn2 &lt;- 20\n\n\n\nShow the code# Calculate the mean difference\nMD &lt;- mean(x1) - mean(x2)\nMD\n\n[1] -4.421357\n\nShow the code# Calculate s_pooled\ns_pooled &lt;- sqrt(\n  (((n1-1)*s1^2) + ((n2-1)*s2^2))/\n    ((n1-1)+(n2-1))\n)\n\n# Calculate the standard error\nse &lt;- s_pooled*sqrt((1/n1)+(1/n2))\nse\n\n[1] 0.8577262\n\n\n对于均差的荟萃分析，我们只需要在数据集中准备以下列：\n\nn.e. 干预/实验组中的观察值数量。\nmean.e. 干预/实验组的平均值。\nsd.e. 干预/实验组的标准差。\nn.c. 对照组中的观测值个数。\nmean.c. 对照组的均值。\nsd.c. 控制组中的标准差。\n组间标准化均值差值\n在文献中，标准化均值差也通常称为 Cohen's d 。\n\\[\n\\text{SMD}_{\\text{between}} = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{\\text{pooled}}}\n\\]\n通常使用 Cohen （1988） 的约定进行解释：\n\nSMD ≈ 0.20: small effect.\nSMD ≈ 0.50: moderate effect.\nSMD ≈ 0.80: large effect.\n\n\\[\nSE_{\\text{SMD}_{\\text{between}}} = \\sqrt{\\frac{n_1+n_2}{n_1n_2} + \\frac{\\text{SMD}^2_{\\text{between}}}{2(n_1+n_2)}}\n\\]\n\nShow the codelibrary(esc)\n\n# This is just some example data that we made up\ngrp1m &lt;- 50   # mean of group 1\ngrp2m &lt;- 60   # mean of group 2\ngrp1sd &lt;- 10  # sd of group 1\ngrp2sd &lt;- 10  # sd of group 2\ngrp1n &lt;- 100  # n of group1\ngrp2n &lt;- 100  # n of group2\n\n# Calculate effect size\nesc_mean_sd(grp1m = grp1m, grp2m = grp2m, \n            grp1sd = grp1sd, grp2sd = grp2sd, \n            grp1n = grp1n, grp2n = grp2n)\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: mean and sd to effect size d\n    Effect Size:  -1.0000\n Standard Error:   0.1500\n       Variance:   0.0225\n       Lower CI:  -1.2940\n       Upper CI:  -0.7060\n         Weight:  44.4444\n\n\n小样本校正，Hedges’g\n要对标准化均数差进行荟萃分析，我们的数据集至少应包含以下列：\n\nn.e. 干预/实验组中的观察值数量。\nmean.e. 干预/实验组的平均值。\nsd.e. 干预/实验组的标准差。\nn.c. 对照组中的观测值个数。\nmean.c. 对照组的均值。\nsd.c. 控制组中的标准差。\n组内（标准化）均值差值\n当在两个不同的时间点（例如，干预前和干预后）测量同一组人时，通常会出现这种情况。\n\\[\n\\text{MD}_{\\text{within}} = \\bar{x}_{\\text{t}_2} - \\bar{x}_{\\text{t}_1}\n\\]\n(对数)风险比\n\n\n\nEvent\nNo Event\n\n\n\n\nTreatment\na\nb\nn treatntreat\n\n\nControl\nc\nd\nn control\n\n\n\nn E\nn¬E\n\n\n\n\n\\[\n{p_{E}}_{\\text{treat}} = \\frac{a}{a+b} = \\frac{a}{n_{\\text{treat}}}\n\\]\n\\[\n{p_{E}}_{\\text{control}} = \\frac{c}{c+d} = \\frac{c}{n_{\\text{control}}}\n\\]\n\\[\n\\text{RR} = \\frac{{p_{E}}_{\\text{treat}}}{{p_{E}}_{\\text{control}}}\n\\]\n\nShow the code# Define data\na &lt;- 46         # events in the treatment group\nc &lt;- 77         # events in the control group\nn_treat &lt;- 248  # sample size treatment group\nn_contr &lt;- 251  # sample size control group\n\n# Calculate the risks\np_treat &lt;- a/n_treat\np_contr &lt;- c/n_contr\n\n# Calculate the risk ratio\nrr &lt;- p_treat/p_contr\nrr\n\n[1] 0.6046292\n\n\nlog-risk ratio\n\\[\n\\log \\text{RR}  = \\log_{e}(\\text{RR})\n\\]\n\\[\nSE_{\\log \\text{RR}} = \\sqrt{\\frac{1}{a}+\\frac{1}{c} - \\frac{1}{a+b} - \\frac{1}{c+d}}\n\\]\n\nShow the code# Calculate the log-risk ratio and its standard error\nlog_rr &lt;- log(rr)\nlog_rr\n\n[1] -0.5031398\n\nShow the codese_log_rr &lt;- sqrt((1/a) + (1/c) - (1/n_treat) - (1/n_contr))\nse_log_rr\n\n[1] 0.1634314\n\n\ncontinuity correction\ntreatment arm continuity correction\n(fixed-effect) Mantel-Haenszel method\n我们的数据集中应包含以下列：\n\nevent.e. 处理组或实验组中的事件数。\nn.e. 处理组或实验组的样本量。\nevent.c. 控制组中的事件数。\nn.c. 对照组的样本量。\n比值比\n\\[\n\\text{OR} = \\frac{a/b}{c/d}\n\\]\n\\[\n\\log \\text{OR}  = \\log_{e}(\\text{OR})\n\\]\n\\[\nSE_{\\log \\text{OR}}  = \\sqrt{\\frac{1}{a}+\\frac{1}{b}+\\frac{1}{c}+\\frac{1}{d}}\n\\]\n\nShow the codelibrary(esc)\n\n# Define data\ngrp1yes &lt;- 45  # events in the treatment group\ngrp1no &lt;- 98   # non-events in the treatment group\ngrp2yes &lt;- 67  # events in the control group\ngrp2no &lt;- 76   # non-events in the control group\n\n# Calculate OR by setting es.type to \"or\"\nesc_2x2(grp1yes = grp1yes, grp1no = grp1no,\n        grp2yes = grp2yes, grp2no = grp2no,\n        es.type = \"or\")\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: 2x2 table (OR) coefficient to effect size odds ratio\n    Effect Size:   0.5209\n Standard Error:   0.2460\n       Variance:   0.0605\n       Lower CI:   0.3216\n       Upper CI:   0.8435\n         Weight:  16.5263\n\n\n\\[\n\\text{RR} = \\frac{\\text{OR}}{\\left(1-\\dfrac{c}{n_{\\text{control}}}\\right)+ \\left(\\dfrac{c}{n_{\\text{control}}}\\times \\text{OR} \\right)}\n\\]\n为了对 R 中的比值比进行荟萃分析，我们的数据集中应包括以下列：\n\nevent.e. 处理组或实验组中的事件数。\nn.e. 处理组或实验组的样本量。\nevent.c. 控制组中的事件数。\nn.c. 对照组的样本量。\n发病率比 Incidence Rate Ratios"
  },
  {
    "objectID": "posts/MetaAnalysis/effect_sizes.html#校正",
    "href": "posts/MetaAnalysis/effect_sizes.html#校正",
    "title": "效应大小",
    "section": "校正",
    "text": "校正\n小样本偏倚\nHedges’g\n\\[\ng = \\text{SMD} \\times (1-\\frac{3}{4n-9})\n\\]\n\nShow the code# Load esc package\nlibrary(esc)\n\n# Define uncorrected SMD and sample size n\nSMD &lt;- 0.5\nn &lt;- 30\n\n# Convert to Hedges g\ng &lt;- hedges_g(SMD, n)\ng\n\n[1] 0.4864865\n\n\n不可靠\nreliability coefficient rxx test-retest-reliability\nHunter 和 Schmidt 方法 attenuation\n计算相关性的校正版本\n\\[\n{r_{xy}}_{c} = \\frac{r_{xy}}{\\sqrt{r_{xx}}}\n\\]\n\\[\n{r_{xy}}_{c} = \\frac{r_{xy}}{\\sqrt{r_{xx}}\\sqrt{r_{yy}}}\n\\]\n当结果x在两组中观察到\n\\[\n\\text{SMD}_c = \\frac{\\text{SMD}}{\\sqrt{r_{xx}}}\n\\]\n标准误的校正\n\\[\nSE_c = \\frac{SE}{\\sqrt{r_{xx}}}\n\\]\n\\[\nSE_c = \\frac{SE}{\\sqrt{r_{xx}}\\sqrt{r_{yy}}}\n\\]\n\nShow the code# Define uncorrected correlation and SMD with their standard error\nr_xy &lt;- 0.34\nse_r_xy &lt;- 0.09\nsmd &lt;- 0.65\nse_smd &lt;- 0.18\n\n# Define reliabilities of x and y\nr_xx &lt;- 0.8\nr_yy &lt;- 0.7\n\n# Correct SMD for unreliability in x\nsmd_c &lt;- smd/sqrt(r_xx)\nsmd_c\n\n[1] 0.7267221\n\nShow the codese_c &lt;- se_smd/sqrt(r_xx)\nse_c\n\n[1] 0.2012461\n\n\n\nShow the code# Correct correlation for unreliability in x and y\nr_xy_c &lt;- r_xy/(sqrt(r_xx)*sqrt(r_yy))\nr_xy_c\n\n[1] 0.4543441\n\n\n\nShow the codese_c &lt;- se_r_xy/(sqrt(r_xx)*sqrt(r_yy))\nse_c\n\n[1] 0.1202676\n\n\n范围限制\n\\[\nU =  \\frac{s_{\\text{unrestricted}}}{s_{\\text{restricted}}}\n\\]\n\\[\n{r_{xy}}_c = \\frac{U\\times r_{xy}}{\\sqrt{(U^2-1)r_{xy}^2+1}}\n\\]\n\\[\n\\text{SMD}_c = \\frac{U\\times \\text{SMD}}{\\sqrt{(U^2-1)\\text{SMD}^2+1}}\n\\]\n\\[\nSE_{{r_{xy}}_c} = \\frac{{r_{xy}}_c}{r_{xy}}SE_{r_{xy}}\n\\]\n\\[\nSE_{{\\text{SMD}}_c} = \\frac{{\\text{SMD}}_c}{\\text{SMD}}SE_{\\text{SMD}}\n\\]\n\nShow the code# Define correlation to correct\nr_xy &lt;- 0.34\nse_r_xy &lt;- 0.09\n\n# Define restricted and unrestricted SD\nsd_restricted &lt;- 11\nsd_unrestricted &lt;- 18\n\n# Calculate U\nU &lt;- sd_unrestricted/sd_restricted\n\n# Correct the correlation\nr_xy_c &lt;- (U*r_xy)/sqrt((U^2-1)*r_xy^2+1)\nr_xy_c\n\n[1] 0.5091754\n\nShow the code# Correct the standard error\nse_r_xy_c &lt;- (r_xy_c/r_xy)*se_r_xy\nse_r_xy_c\n\n[1] 0.1347817"
  },
  {
    "objectID": "posts/MetaAnalysis/Meta_Regression.html",
    "href": "posts/MetaAnalysis/Meta_Regression.html",
    "title": "Meta 回归",
    "section": "",
    "text": "Meta-regression 通过假设混合效应模型来实现。由于抽样误差和研究之间的异质性，观察到的研究偏离了真实的总体效应。\n普通最小二乘法的加权版本\nmeta 回归 使用一个或多个变量x来预测真实效应大小的差异。\n\\[\n\\hat\\theta_k = \\theta + \\beta x_{k} + \\epsilon_k+\\zeta_k\n\\]\n抽样误差\\(\\epsilon_k\\)和研究间异质性 \\(\\zeta_k\\)\n固定效应（\\(\\beta\\)）和 随机效应（\\(\\zeta_k\\)）"
  },
  {
    "objectID": "posts/MetaAnalysis/SubgroupAnalysis.html",
    "href": "posts/MetaAnalysis/SubgroupAnalysis.html",
    "title": "亚组分析",
    "section": "",
    "text": "亚组分析只是元回归的一个特例\n先验定义\n在亚组分析中，我们假设荟萃分析中的研究不是来自一个总体人群。 相反，我们假设它们属于不同的子组，每个子组都有自己的真实整体效应。 目的是拒绝亚组之间效应大小没有差异的零假设。"
  },
  {
    "objectID": "posts/MetaAnalysis/SubgroupAnalysis.html#固定效应复数模型",
    "href": "posts/MetaAnalysis/SubgroupAnalysis.html#固定效应复数模型",
    "title": "亚组分析",
    "section": "固定效应（复数）模型",
    "text": "固定效应（复数）模型\nThe Fixed-Effects (Plural) Model\n固定效应（复数）模型包含随机效应（子组内）和固定效应（因为子组被假设为固定的），因此在文献中也称为混合效应模型。\n添加“复数”一词是因为我们必须将其与标准固定效应模型区分开来。固定效应（复数）模型可以看作是一种混合生物，包括固定效应模型和随机效应模型的特征。与随机效应模型一样，我们假设存在多个真实效应大小，因为我们的数据中有子组。\n子组分析的计算由两部分组成：首先，我们将每个子组中的效应合并。随后，使用统计测试来比较亚组的效果\nPooling the Effect in Subgroups\n\na pooled effect \\(\\hat μ_g\\) for each subgroup \\(g\\) .\nshare a common estimate of the between-study heterogeneity \\(\\tau^2\\) that was pooled across subgroups\n\nComparing the Subgroup Effects using a statistical test\n\nQ test ：自由度为G-1的卡方分布\n\n\n\n\n\n\n\nCaution\n\n\n\n子组分析：注意 事项\n\n子组分析取决于统计功效，因此它通常 当研究数量很少时进行一次研究是没有意义的 （即K&lt; 10）。\n\n\n如果未发现子组之间的效应大小存在差异， 这并不意味着子组 产生等效的结果。\n\n\n亚组分析纯粹是观察性的，因此，我们应该始终牢记，效果差异也可能是由混杂变量引起的\n在亚组分析中使用汇总研究信息是一个坏主意，因为这可能会引入系统偏差。"
  },
  {
    "objectID": "posts/MetaAnalysis/SubgroupAnalysis.html#r",
    "href": "posts/MetaAnalysis/SubgroupAnalysis.html#r",
    "title": "亚组分析",
    "section": "R",
    "text": "R\n\nShow the code# Show first entries of study name and 'RiskOfBias' column\nhead(dmetar::ThirdWave[,c(\"Author\", \"RiskOfBias\")])\n\n           Author RiskOfBias\n1     Call et al.       high\n2 Cavanagh et al.        low\n3   DanitzOrsillo       high\n4  de Vibe et al.        low\n5  Frazier et al.        low\n6  Frogeli et al.        low\n\n\n\nShow the codelibrary(meta)\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = dmetar::ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 prediction = TRUE,\n                 title = \"Third Wave Psychotherapies\")\n\n\n\nShow the codeupdate(m.gen, \n       subgroup = RiskOfBias, \n       tau.common = FALSE)\n\nReview:     Third Wave Psychotherapies\n\nNumber of studies: k = 18\n\n                             SMD            95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [ 0.3782; 0.7760] 6.12 &lt; 0.0001\nPrediction interval              [-0.0542; 1.2084]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nResults for subgroups (random effects model (HK)):\n                    k    SMD           95%-CI  tau^2    tau     Q   I^2\nRiskOfBias = high   7 0.8126 [0.2835; 1.3417] 0.2423 0.4922 25.89 76.8%\nRiskOfBias = low   11 0.4300 [0.2770; 0.5830] 0.0099 0.0997 13.42 25.5%\n\nTest for subgroup differences (random effects model (HK)):\n                  Q d.f. p-value\nBetween groups 2.84    1  0.0917\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 17)\n- Prediction interval based on t-distribution (df = 17)\n\n\n\nShow the codeupdate(m.gen, subgroup = RiskOfBias, tau.common = TRUE)\n\nReview:     Third Wave Psychotherapies\n\nNumber of studies: k = 18\n\n                             SMD            95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [ 0.3782; 0.7760] 6.12 &lt; 0.0001\nPrediction interval              [-0.0542; 1.2084]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nQuantifying residual heterogeneity (with 95%-CIs):\n tau^2 = 0.0691 [0.0208; 0.3268]; tau = 0.2630 [0.1441; 0.5717]\n I^2 = 59.3% [30.6%; 76.1%]; H = 1.57 [1.20; 2.05]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nResults for subgroups (random effects model (HK)):\n                    k    SMD           95%-CI  tau^2    tau     Q   I^2\nRiskOfBias = high   7 0.7691 [0.2533; 1.2848] 0.0691 0.2630 25.89 76.8%\nRiskOfBias = low   11 0.4698 [0.3015; 0.6382] 0.0691 0.2630 13.42 25.5%\n\nTest for subgroup differences (random effects model (HK)):\n                   Q d.f. p-value\nBetween groups  1.79    1  0.1814\nWithin groups  39.31   16  0.0010\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n  (assuming common tau^2 in subgroups)\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 17)\n- Prediction interval based on t-distribution (df = 17)"
  },
  {
    "objectID": "posts/Software/RecCloud.html",
    "href": "posts/Software/RecCloud.html",
    "title": "睿客云盘",
    "section": "",
    "text": "睿客网（REC），即中国科学技术大学科研教学资源中心，为科大师生用户提供数据存储、备份、分享等服务的在线平台。"
  },
  {
    "objectID": "posts/Statistics/margin_mean_effect.html#边际效应",
    "href": "posts/Statistics/margin_mean_effect.html#边际效应",
    "title": "边际效应",
    "section": "边际效应",
    "text": "边际效应\nggeffects 描述单个自变量的作用，Petal.Length 对Petal.Width 的边际效应\n\nShow the codelibrary(ggeffects)\npred &lt;- ggpredict(m, terms = \"Petal.Length\")\nggplot(pred, aes(x, predicted)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.1) +\n  theme_classic() +\n  labs(x = \"Petal.Length\", y = \"Petal.Width\")"
  },
  {
    "objectID": "posts/MetaAnalysis/PublicationBias.html#p-曲线",
    "href": "posts/MetaAnalysis/PublicationBias.html#p-曲线",
    "title": "发表偏倚",
    "section": "P 曲线",
    "text": "P 曲线"
  },
  {
    "objectID": "posts/MetaAnalysis/PublicationBias.html#选择模型",
    "href": "posts/MetaAnalysis/PublicationBias.html#选择模型",
    "title": "发表偏倚",
    "section": "选择模型",
    "text": "选择模型"
  },
  {
    "objectID": "posts/MetaAnalysis/Meta_Regression.html#meta回归模型",
    "href": "posts/MetaAnalysis/Meta_Regression.html#meta回归模型",
    "title": "Meta 回归",
    "section": "Meta回归模型",
    "text": "Meta回归模型\n使用分类预测因子的meta回归\n\\[\n\\begin{equation}   \nD_g=\\begin{cases}     \n0: & \\text{Subgroup A}\\\\     \n1: & \\text{Subgroup B.}   \n\\end{cases}   \n\\end{equation}\n\\]\n\\[\n\\begin{equation} \\hat\\theta_k = \\theta + \\beta D_g +\\epsilon_k+\\zeta_k.  \\end{equation}\n\\]\n则\n\\[\n\\begin{equation}   D_g=\\begin{cases}     0: & \\text{$\\hat\\theta_k = \\theta_A + \\epsilon_k+\\zeta_k$}\\\\     1: & \\text{$\\hat\\theta_k = \\theta_B + \\theta_{\\Delta} +\\epsilon_k+\\zeta_k$}   \\end{cases}   \\end{equation}\n\\]\n\n\n\n\n使用连续预测因子的meta回归\n\n\n\n\n\nShow the codelibrary(meta)\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = dmetar::ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 method.random.ci = \"HK\",\n                 prediction = T,\n                 title = \"Third Wave Psychotherapies\")\nsummary(m.gen)\n\nReview:     Third Wave Psychotherapies\n\n                          SMD            95%-CI %W(random)\nCall et al.            0.7091 [ 0.1979; 1.2203]        5.0\nCavanagh et al.        0.3549 [-0.0300; 0.7397]        6.3\nDanitzOrsillo          1.7912 [ 1.1139; 2.4685]        3.8\nde Vibe et al.         0.1825 [-0.0484; 0.4133]        7.9\nFrazier et al.         0.4219 [ 0.1380; 0.7057]        7.3\nFrogeli et al.         0.6300 [ 0.2458; 1.0142]        6.3\nGallego et al.         0.7249 [ 0.2846; 1.1652]        5.7\nHazlett-Stevens & Oren 0.5287 [ 0.1162; 0.9412]        6.0\nHintz et al.           0.2840 [-0.0453; 0.6133]        6.9\nKang et al.            1.2751 [ 0.6142; 1.9360]        3.9\nKuhlmann et al.        0.1036 [-0.2781; 0.4853]        6.3\nLever Taylor et al.    0.3884 [-0.0639; 0.8407]        5.6\nPhang et al.           0.5407 [ 0.0619; 1.0196]        5.3\nRasanen et al.         0.4262 [-0.0794; 0.9317]        5.1\nRatanasiripong         0.5154 [-0.1731; 1.2039]        3.7\nShapiro et al.         1.4797 [ 0.8618; 2.0977]        4.2\nSong & Lindquist       0.6126 [ 0.1683; 1.0569]        5.7\nWarnecke et al.        0.6000 [ 0.1120; 1.0880]        5.2\n\nNumber of studies: k = 18\n\n                             SMD            95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [ 0.3782; 0.7760] 6.12 &lt; 0.0001\nPrediction interval              [-0.0542; 1.2084]              \n\nQuantifying heterogeneity (with 95%-CIs):\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nDetails of meta-analysis methods:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Calculation of I^2 based on Q\n- Hartung-Knapp adjustment for random effects model (df = 17)\n- Prediction interval based on t-distribution (df = 17)\n\n\n\nShow the codeyear &lt;- c(2014, 1998, 2010, 1999, 2005, 2014, \n          2019, 2010, 1982, 2020, 1978, 2001,\n          2018, 2002, 2009, 2011, 2011, 2013)\n\nm.gen.reg &lt;- metareg(m.gen, ~year)\nm.gen.reg\n\n\nMixed-Effects Model (k = 18; tau^2 estimator: REML)\n\ntau^2 (estimated amount of residual heterogeneity):     0.0188 (SE = 0.0226)\ntau (square root of estimated tau^2 value):             0.1371\nI^2 (residual heterogeneity / unaccounted variability): 29.26%\nH^2 (unaccounted variability / sampling variability):   1.41\nR^2 (amount of heterogeneity accounted for):            77.08%\n\nTest for Residual Heterogeneity:\nQE(df = 16) = 27.8273, p-val = 0.0332\n\nTest of Moderators (coefficient 2):\nF(df1 = 1, df2 = 16) = 9.3755, p-val = 0.0075\n\nModel Results:\n\n         estimate       se     tval  df    pval     ci.lb     ci.ub     \nintrcpt  -36.1546  11.9800  -3.0179  16  0.0082  -61.5510  -10.7582  ** \nyear       0.0183   0.0060   3.0619  16  0.0075    0.0056    0.0310  ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\\(\\hat\\tau^2_{\\text{unexplained}}=\\) 0.0188\n\\(R^2_*\\) =77.08% 意味着真实效应大小的 77% 的差异可以用出版年份来解释，这是一个相当大的值。\n\nShow the codebubble(m.gen.reg, studlab = TRUE)\n\n\n\n\n\n\n\n\nShow the code# 通过meta回归进行亚组分析\nmetareg(m.gen, RiskOfBias)\n\n\nMixed-Effects Model (k = 18; tau^2 estimator: REML)\n\ntau^2 (estimated amount of residual heterogeneity):     0.0691 (SE = 0.0424)\ntau (square root of estimated tau^2 value):             0.2630\nI^2 (residual heterogeneity / unaccounted variability): 60.58%\nH^2 (unaccounted variability / sampling variability):   2.54\nR^2 (amount of heterogeneity accounted for):            15.66%\n\nTest for Residual Heterogeneity:\nQE(df = 16) = 39.3084, p-val = 0.0010\n\nTest of Moderators (coefficient 2):\nF(df1 = 1, df2 = 16) = 2.5066, p-val = 0.1329\n\nModel Results:\n\n               estimate      se     tval  df    pval    ci.lb   ci.ub      \nintrcpt          0.7691  0.1537   5.0022  16  0.0001   0.4431  1.0950  *** \nRiskOfBiaslow   -0.2992  0.1890  -1.5832  16  0.1329  -0.6999  0.1014      \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nRiskOfBiaslow 效应大小 g = 0.7691-0.2992 ≈0.4699"
  },
  {
    "objectID": "posts/MetaAnalysis/Meta_Regression.html#多元回归",
    "href": "posts/MetaAnalysis/Meta_Regression.html#多元回归",
    "title": "Meta 回归",
    "section": "多元回归",
    "text": "多元回归\n\\[\n\\begin{equation} \\hat \\theta_k = \\theta + \\beta_1x_{1k} + ... + \\beta_nx_{nk} + \\epsilon_k + \\zeta_k \\tag{multiple-metareg} \\end{equation}\n\\]\n\nShow the codelibrary(metafor)\nlibrary(tidyverse)\nlibrary(dmetar)\ndata(MVRegressionData)\nglimpse(MVRegressionData)\n\nRows: 36\nColumns: 6\n$ yi         &lt;dbl&gt; 0.09437543, 0.09981923, 0.16931607, 0.17511107, 0.27301641,…\n$ sei        &lt;dbl&gt; 0.1959031, 0.1918510, 0.1193179, 0.1161592, 0.1646946, 0.17…\n$ reputation &lt;dbl&gt; -11, 0, -11, 4, -10, -9, -8, -8, -8, 0, -5, -5, -4, -4, -3,…\n$ quality    &lt;dbl&gt; 6, 9, 5, 9, 2, 10, 6, 3, 10, 3, 1, 5, 10, 2, 1, 2, 4, 1, 8,…\n$ pubyear    &lt;dbl&gt; -0.85475360, -0.75277184, -0.66048349, -0.56304843, -0.4308…\n$ continent  &lt;fct&gt; 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,…\n\n\n多重共线性\n\nShow the codeMVRegressionData[,c(\"reputation\", \"quality\", \"pubyear\")] %&gt;% \n    cor()\n\n           reputation    quality    pubyear\nreputation  1.0000000  0.3015694  0.3346594\nquality     0.3015694  1.0000000 -0.1551123\npubyear     0.3346594 -0.1551123  1.0000000\n\n\n\nShow the codem.qual &lt;- rma(yi = yi,\n              sei = sei,\n              data = MVRegressionData,\n              method = \"ML\",\n              mods = ~ quality,\n              test = \"knha\")\n\nm.qual\n\n\nMixed-Effects Model (k = 36; tau^2 estimator: ML)\n\ntau^2 (estimated amount of residual heterogeneity):     0.0667 (SE = 0.0275)\ntau (square root of estimated tau^2 value):             0.2583\nI^2 (residual heterogeneity / unaccounted variability): 60.04%\nH^2 (unaccounted variability / sampling variability):   2.50\nR^2 (amount of heterogeneity accounted for):            7.37%\n\nTest for Residual Heterogeneity:\nQE(df = 34) = 88.6130, p-val &lt; .0001\n\nTest of Moderators (coefficient 2):\nF(df1 = 1, df2 = 34) = 3.5330, p-val = 0.0688\n\nModel Results:\n\n         estimate      se    tval  df    pval    ci.lb   ci.ub    \nintrcpt    0.3429  0.1354  2.5318  34  0.0161   0.0677  0.6181  * \nquality    0.0356  0.0189  1.8796  34  0.0688  -0.0029  0.0740  . \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nShow the codem.qual.rep &lt;- rma(yi = yi, \n                  sei = sei, \n                  data = MVRegressionData, \n                  method = \"ML\", \n                  mods = ~ quality + reputation, \n                  test = \"knha\")\n\nm.qual.rep\n\n\nMixed-Effects Model (k = 36; tau^2 estimator: ML)\n\ntau^2 (estimated amount of residual heterogeneity):     0.0238 (SE = 0.0161)\ntau (square root of estimated tau^2 value):             0.1543\nI^2 (residual heterogeneity / unaccounted variability): 34.62%\nH^2 (unaccounted variability / sampling variability):   1.53\nR^2 (amount of heterogeneity accounted for):            66.95%\n\nTest for Residual Heterogeneity:\nQE(df = 33) = 58.3042, p-val = 0.0042\n\nTest of Moderators (coefficients 2:3):\nF(df1 = 2, df2 = 33) = 12.2476, p-val = 0.0001\n\nModel Results:\n\n            estimate      se    tval  df    pval    ci.lb   ci.ub      \nintrcpt       0.5005  0.1090  4.5927  33  &lt;.0001   0.2788  0.7222  *** \nquality       0.0110  0.0151  0.7312  33  0.4698  -0.0197  0.0417      \nreputation    0.0343  0.0075  4.5435  33  &lt;.0001   0.0189  0.0496  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nShow the codeanova(m.qual, m.qual.rep)\n\n\n        df     AIC     BIC    AICc   logLik     LRT   pval      QE  tau^2 \nFull     4 19.4816 25.8157 20.7720  -5.7408                58.3042 0.0238 \nReduced  3 36.9808 41.7314 37.7308 -15.4904 19.4992 &lt;.0001 88.6130 0.0667 \n             R^2 \nFull             \nReduced 64.3197% \n\n\nanova LRT X2= 19.4992 ,p&lt;0.001\n交互效应\n\nShow the code# Add factor labels to 'continent'\n# 0 = Europe\n# 1 = North America\nlevels(MVRegressionData$continent) = c(\"Europe\", \"North America\")\n\n# Fit the meta-regression model\nm.qual.rep.int &lt;- rma(yi = yi, \n                      sei = sei, \n                      data = MVRegressionData, \n                      method = \"REML\", \n                      mods = ~ pubyear * continent, \n                      test = \"knha\")\n\nm.qual.rep.int\n\n\nMixed-Effects Model (k = 36; tau^2 estimator: REML)\n\ntau^2 (estimated amount of residual heterogeneity):     0 (SE = 0.0098)\ntau (square root of estimated tau^2 value):             0\nI^2 (residual heterogeneity / unaccounted variability): 0.00%\nH^2 (unaccounted variability / sampling variability):   1.00\nR^2 (amount of heterogeneity accounted for):            100.00%\n\nTest for Residual Heterogeneity:\nQE(df = 32) = 24.8408, p-val = 0.8124\n\nTest of Moderators (coefficients 2:4):\nF(df1 = 3, df2 = 32) = 28.7778, p-val &lt; .0001\n\nModel Results:\n\n                                estimate      se    tval  df    pval    ci.lb \nintrcpt                           0.3892  0.0421  9.2472  32  &lt;.0001   0.3035 \npubyear                           0.1683  0.0834  2.0184  32  0.0520  -0.0015 \ncontinentNorth America            0.3986  0.0658  6.0539  32  &lt;.0001   0.2645 \npubyear:continentNorth America    0.6323  0.1271  4.9754  32  &lt;.0001   0.3734 \n                                 ci.ub      \nintrcpt                         0.4750  *** \npubyear                         0.3380    . \ncontinentNorth America          0.5327  *** \npubyear:continentNorth America  0.8911  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n过拟合\n\\(R^2_*\\) = 100% ，在实践中，几乎不会解释数据中的所有异质性——事实上，如果在现实生活中的数据中找到这样的结果，这可能是模型过度拟合了。\n排列测试\n\nShow the codepermutest(m.qual.rep)\n\nRunning 1000 iterations for an approximate permutation test.\n\n\n\nTest of Moderators (coefficients 2:3):¹\nF(df1 = 2, df2 = 33) = 12.2476, p-val = 0.0010\n\nModel Results:\n\n            estimate      se    tval  df    pval¹    ci.lb   ci.ub      \nintrcpt       0.5005  0.1090  4.5927  33  0.1980    0.2788  0.7222      \nquality       0.0110  0.0151  0.7312  33  0.4090   -0.0197  0.0417      \nreputation    0.0343  0.0075  4.5435  33  0.0010    0.0189  0.0496  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n1) p-values based on permutation testing\n\n\n多模型推理\n\nShow the codemultimodel.inference(TE = \"yi\", \n                     seTE = \"sei\",\n                     data = MVRegressionData,\n                     predictors = c(\"pubyear\", \"quality\", \n                                    \"reputation\", \"continent\"),\n                     interaction = FALSE)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |============================================                          |  62%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=============================================================         |  88%\n  |                                                                            \n  |==================================================================    |  94%\n\n\n\n\nMultimodel Inference: Final Results\n--------------------------\n\n - Number of fitted models: 16\n - Full formula: ~ pubyear + quality + reputation + continent\n - Coefficient significance test: knha\n - Interactions modeled: no\n - Evaluation criterion: AICc \n\n\nBest 5 Models\n--------------------------\n\n\nGlobal model call: metafor::rma(yi = TE, sei = seTE, mods = form, data = glm.data, \n    method = method, test = test)\n---\nModel selection table \n   (Intrc) cntnn  pubyr   qulty   rpttn df logLik AICc delta weight\n12       +     + 0.3533         0.02160  5  2.981  6.0  0.00  0.536\n16       +     + 0.4028 0.02210 0.01754  6  4.071  6.8  0.72  0.375\n8        +     + 0.4948 0.03574          5  0.646 10.7  4.67  0.052\n11       +       0.2957         0.02725  4 -1.750 12.8  6.75  0.018\n15       +       0.3547 0.02666 0.02296  5 -0.395 12.8  6.75  0.018\nModels ranked by AICc(x) \n\n\nMultimodel Inference Coefficients\n--------------------------\n\n                         Estimate  Std. Error   z value  Pr(&gt;|z|)\nintrcpt                0.38614661 0.106983583 3.6094006 0.0003069\ncontinentNorth America 0.24743836 0.083113174 2.9771256 0.0029096\npubyear                0.37816796 0.083045572 4.5537402 0.0000053\nreputation             0.01899347 0.007420427 2.5596198 0.0104787\nquality                0.01060060 0.014321158 0.7402055 0.4591753\n\n\nPredictor Importance\n--------------------------\n\n       model importance\n1    pubyear  0.9988339\n2  continent  0.9621839\n3 reputation  0.9428750\n4    quality  0.4432826"
  }
]